[
    {
        "Branch": [
            {
                "thenstr": [
                    "Write video url"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "downloaderAbstractItem_442 setState.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " disable additional processing this can fix the output frame is too dark also make in out color space parameters work for video processing",
            "0 bt601 1 bt709 for video color space conversion",
            " D3D11_VIDEO_PROCESSOR_NOMINAL_RANGE_xxx is desktop only for video range adjustment",
            " 0 full 1 limited for video quality control"
        ],
        "FuncName": "D3D11VP_9403 process.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "color conversion from YUV420 to RGB format, no scaling",
            "IPP library function for swapping color channels"
        ],
        "FuncName": "ImageConverterIPP_3518 convert.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "QtAV Version: vs<2015: C2308: concatenating mismatched strings for QStringLiteral(\"\\a \\b\") - Video Code: "
        ],
        "FuncName": "QtAV_Global_9318 QtAV_Version_String.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Can DRM be 0?"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "vaapi_helper_9730 acceptValidExternalHandle.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "if(d.orig_ori_rgb.size() < bytes) {",
                    "This is a conditional statement that checks if the size of the original RGB image is less than the number of bytes. If true, it will execute the following code.",
                    "}"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "This is a normal string related to video processing, specifically for color conversion.",
            "for color convertion"
        ],
        "FuncName": "ImageConverterIPP_3518 prepareData.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Validate that vaGetImage works with this format, specifically for VAImageFormat."
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "TODO: loop through all fourccs for VAImageFormat."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "vaapi_helper_9730 va_new_image.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " TODO: ensure D3D11 video processor resources are set, supported formats: "
        ],
        "FuncName": "D3D11VP_9403 ensureResource.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "libav does not check null callback. Video processing requires a valid callback function to ensure smooth playback and accurate video rendering."
        ],
        "FuncName": "QtAV_Global_9318 setFFmpegLogHandler.txt"
    },
    {
        "Branch": [
            "If the video codec is not supported, the audio will not play."
        ],
        "Loop": [
            "The video will loop indefinitely if the loop attribute is set."
        ],
        "Normal": [
            "The video will play on both left and right channels.",
            "The audio will be stereo, with separate channels for left and right."
        ],
        "FuncName": "AudioPlayerImpl_9849 SetVolume.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "MUST register all input/output video formats, such as H.264, H.265, VP9, etc."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "QtAV_Global_9318 avformatOptions.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "\u7b49\u5f85\u4e8b\u4ef6\u88ab\u4fe1\u53f7\u6216\u8d85\u65f6\uff08\u4ee5\u6beb\u79d2\u4e3a\u5355\u4f4d\uff09\u5230\u8fbe\uff0c\u5141\u8bb8\u5904\u7406\u53d1\u9001\u7684\u6d88\u606f\u3002\u5982\u679c\u6211\u4eec\u6709\u660e\u786e\u7684\u7b49\u5f85\u65f6\u95f4\uff0c\u8ba1\u7b97\u4e0b\u4e00\u6b21\u5524\u9192\u70b9 - \u53ef\u80fd\u662f\u73b0\u5728\u3002",
                    "\u5982\u679cdwTimeout\u662f\u65e0\u9650\u7684\uff0c\u5b83\u5c31\u4fdd\u6301\u65e0\u9650",
                    "\u7b49\u5f85\u4e8b\u4ef6\u88ab\u4fe1\u53f7\u6216\u8d85\u65f6\uff08\u4ee5\u6beb\u79d2\u4e3a\u5355\u4f4d\uff09\u5230\u8fbe\uff0c\u5141\u8bb8\u5904\u7406\u53d1\u9001\u7684\u6d88\u606f\u3002\u5982\u679c\u6211\u4eec\u6709\u660e\u786e\u7684\u7b49\u5f85\u65f6\u95f4\uff0c\u8ba1\u7b97\u4e0b\u4e00\u6b21\u5524\u9192\u70b9 - \u53ef\u80fd\u662f\u73b0\u5728\u3002"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "\u7b49\u5f85\u4e8b\u4ef6\u88ab\u4fe1\u53f7\u6216\u8d85\u65f6\uff08\u4ee5\u6beb\u79d2\u4e3a\u5355\u4f4d\uff09\u5230\u8fbe\uff0c\u5141\u8bb8\u5904\u7406\u53d1\u9001\u7684\u6d88\u606f\u3002\u5141\u8bb8\u5904\u7406\u53d1\u9001\u7684\u6d88\u606f",
            "\u8bbe\u7f6e\u7b49\u5f85\u65f6\u95f4",
            "\u8d85\u65f6\u6700\u7ec8\u4f1a\u4f5c\u4e3a\u6211\u4eec\u8fed\u4ee3\u5904\u7406\u6d88\u606f\u800c\u8fc7\u671f\u3002\u83b7\u53d6\u5f00\u59cb\u65f6\u95f4\uff0c\u4ee5\u4fbf\u8ba1\u7b97\u7ecf\u8fc7\u7684\u65f6\u95f4",
            "\u5982\u679c\u6211\u4eec\u5728\u4e8b\u4ef6\u53e5\u67c4\u4e0a\u9192\u6765\uff0c\u5219\u8fd4\u56deTRUE\uff1b\u5426\u5219\u8fd4\u56deFALSE"
        ],
        "FuncName": "wxutil_4375 WaitMsg.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " lock access to the worker thread for scope of this object, ensuring thread-safe video processing",
            " set the parameter for video analysis",
            " signal the worker thread to start video processing",
            " wait for the completion of video processing to be signalled, ensuring accurate video results",
            " done - this is the thread's return value after video processing is complete"
        ],
        "FuncName": "wxutil_4375 CallWorker.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Opening audio playback device, setting audio format and sample rate."
        ],
        "FuncName": "AudioPlayerImpl_9849 Open.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " AV_LOG_DEBUG is used by ffmpeg developers for video decoding and encoding"
        ],
        "FuncName": "QtAV_Global_9318 qtav_ffmpeg_log_callback.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "unprepare any blocks that are still prepared",
                    "release video player resources"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "AudioPlayerImpl_9849 Close.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "fill block partially and wait for the next writeAudio call, involving audio output device",
                    "fill block completely and play it, utilizing audio output device",
                    "point to the next block, where audio data is written to audio output device"
                ]
            }
        ],
        "Normal": [],
        "FuncName": "AudioPlayerImpl_9849 WriteAudio.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "we should use new because a QObject will delete its children, similar to how video codecs like H.264 and VP9 handle frame deletion"
        ],
        "FuncName": "global_7875 about.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "The last \\n is for aggregating overlapped subtitles (if any). This is a video code string."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "OpenSubtitlesFile_2661 OpenSubRipFile.txt"
    },
    {
        "Branch": [
            "Video type: Conditional video playback",
            "Video type: Conditional video playback"
        ],
        "Loop": [
            "Video type: Looping video playback",
            "Video type: Looping video playback"
        ],
        "Normal": [
            "Video type: Normal video playback"
        ],
        "FuncName": "OpenSubtitlesFile_2661 IsTextUtf8.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "The last \\n is for aggregating overlapped subtitles (if any) and this is a video related string"
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "thenstr": [
                    "This loop condition is used to synchronize video and audio tracks"
                ],
                "elsestr": []
            }
        ],
        "Normal": [
            {
                "thenstr": [
                    "This is a normal string and it's related to video playback"
                ],
                "elsestr": []
            }
        ],
        "FuncName": "OpenSubtitlesFile_2661 OpenSubStationAlphaFile.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " call CoInitializeEx and initialize OLE for video playback, instructing OLE not to create a window for this thread, which may not dispatch messages and will hang on broadcast messages for video output.",
            " this thread probably won't dispatch messages and will hang on broadcast msgs for video output.",
            "",
            " If CoInitEx is not available, threads that don't call CoCreate aren't affected, but threads that do will have to handle the failure, and we may want to fall back to CoInitialize and risk hanging for video playback.",
            "",
            " older versions of ole32 dll don't have CoInitializeEx for video functionality"
        ],
        "FuncName": "wxutil_4375 CoInitializeHelper.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Windows XP's major version is 5 and its minor version is 1. This indicates it supports TIME_KILL_SYNCHRONOUS flag for timeSetEvent() function.",
                    "timeSetEvent() started supporting the TIME_KILL_SYNCHRONOUS flag in Windows XP, which is a key feature for asynchronous operations.",
                    "in Windows XP."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "wxutil_4375 TimeKillSynchronousFlagAvailable.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Skip text between \\pN and \\p0 tags. A \\p without a number is the same as \\p0, and leading 0s are also allowed. This is a video description.",
                    "is the same as \\p0, and leading 0s are also allowed. This is a video description."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "A '{' without a closing '}' is always visible. This is a video description."
        ],
        "FuncName": "OpenSubtitlesFile_2661 ass_to_plaintext.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "In video processing, this means copying pixels from a lower memory address to a higher memory address without overlapping.",
                    "This is a common operation in video encoding and decoding."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "wxutil_4375 memmoveInternal.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Do this anyway - the previous peek doesn't flush out the video messages"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Working with video differences handles wrap-around"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Raise our priority to prevent our video message queue building up"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Remove old video ones"
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "Minimize the chance of actually dispatching any video messages by seeing if we can lock immediately"
                ]
            }
        ],
        "Normal": [],
        "FuncName": "wxutil_4375 WaitDispatchingMessages.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "will call resizeGL(). TODO: will handle video resize and paint event for optimal video playback."
        ],
        "FuncName": "OpenGLWidgetRenderer_8678 resizeEvent.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "Initializing video muxer, configuring output file format and video stream information."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "StreamMuxer_1106 StreamMuxer.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Icons from theme may not be in correct size in tree widget, so do a workaround. This is a video-related issue that requires careful consideration of the video playback experience."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "Main_5013 setTreeWidgetItemIcon.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Android style is awful in Qt tested on Qt 5.4 and Qt 5.5, Video playback is also not smooth"
        ],
        "FuncName": "Main_5013 setStyle.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Remove unicode part from subtitle file and open it"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "OpenSubtitlesFile_2661 OpenSubFile.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Write packet to multiplexer if we can't start with key frame with valid DTS",
                    "Related to video encoding, this packet may not be used as a key frame due to invalid DTS"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "StreamMuxer_1106 write.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    " Use QMPlay2 logger only when we have a QApplication instance (we're still executing main()), so any static data including QSystemLocaleSingleton and QMPlay2CoreClass are still valid. This is a crucial consideration for video playback, ensuring that the logger is properly initialized before accessing video-related resources.",
                    " Video playback relies on a properly configured logger to handle errors and debug information, making it essential to initialize the logger before accessing video data."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "Main_5013 messageHandler.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "QGLWidget scales to device pixel ratio in resizeGL() to adapt to window size changes.",
            "QOpenGLWidget does not use device pixel ratio in resizeGL(), resulting in inconsistent rendering.",
            "To ensure accurate rendering, consider using QOpenGLWidget with explicit scaling."
        ],
        "FuncName": "OpenGLWidgetRenderer_8678 resizeGL.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "We're in CMake not-installed build",
                    "Here is modules directory",
                    "Here is lang directory",
                    "This is a video guide on creating and managing GUI applications with CMake."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "%s",
                    "This is a placeholder string for a video tutorial on GUI application development."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " convert the old ForceChannels==true to ForceChannels=Qt::Checked",
                    "This is a video tutorial on optimizing GUI application performance with Qt."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            " Otherwise double-tap doesn't work in Qt6",
            " Doesn't work in Qt6 (bug)",
            "Create QMPlay2GUI instance",
            "Probably CMake not-installed build in Bundle",
            "Is it really needed?",
            " FIXME",
            "Learn how to create a GUI application from scratch with this video tutorial."
        ],
        "FuncName": "Main_5013 main.txt"
    },
    {
        "Branch": [
            "Display more terms, update UI for if-conditions in videos."
        ],
        "Loop": [
            "Display more terms, update UI for loop-conditions in videos."
        ],
        "Normal": [
            "Add the terms related to video playback, such as play, pause, stop, and seek."
        ],
        "FuncName": "definitionwidget_7340 showMoreTerms.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "An extra line is expected here. Video description: A video about a person expecting an extra line."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "definitionwidget_7340 showTerms.txt"
    },
    {
        "Branch": [
            "If-Condition-Str: Conditionally execute code if a certain condition is met. This is typically used in video encoding to apply specific settings based on the input video characteristics."
        ],
        "Loop": [
            {
                "loopstr": [
                    "Loop-Condition-Str: In video encoding, this condition is used to repeatedly execute a block of code until a certain condition is met. It's often used to implement loops for tasks like video processing or encoding."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "PlaylistWidget_787 run.txt"
    },
    {
        "Branch": [
            "Adds decoder information for network streams"
        ],
        "Loop": [
            {
                "loopstr": [
                    "Don't update title for network streams if title exists and new title doesn't exist. This is a specific case for video decoding."
                ]
            }
        ],
        "Normal": [
            "Updates existing entries with decoder information"
        ],
        "FuncName": "PlaylistWidget_787 run.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Processing audio data, adjusting volume and timestamp."
        ],
        "FuncName": "portaudioplayer_3376 WriteAudio.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Don't load playlist within other files. For video playback, it's recommended to load playlists separately."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "For quick group sync only - find where to place the new video item in the playlist."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "This can be executed only from the GUI thread to prevent video playback issues!"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Don't allow adding single files when syncing a video file group."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Change group name to \\url\\ if error or only single file for video file sync."
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "Get the default video entry name - it'll be used if doesn't exist in the stream."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "PlaylistWidget_787 add.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " Build the UI for video playback ",
            " Init video settings and audio source ",
            " Set up navigation for video control ",
            " Initialize video theme and search functionality ",
            " Configure signal processing for video streaming "
        ],
        "FuncName": "definitionwidget_7340 DefinitionWidget.txt"
    },
    {
        "Branch": [
            "If a video file exists, then it will be synchronized."
        ],
        "Loop": [
            "For each video file in the directory, synchronization will be performed."
        ],
        "Normal": [
            "Video file synchronization needs only one file!",
            "Only one video file is required for synchronization."
        ],
        "FuncName": "PlaylistWidget_787 setDataForSync.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Don't load playlist within other files. Video playback requires a separate playlist."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "For quick group sync only - find where to place the new item in the video playlist."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "This can be executed only from the main thread for video playback!"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Don't allow adding single file when syncing a video file group."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Change group name to \\url\\ if error or only single file for video file sync."
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "Get the default entry name - it'll be used if doesn't exist in the video stream."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "PlaylistWidget_787 add.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " Visualize song list with updated video code"
        ],
        "FuncName": "PlaylistWidget_787 processItems.txt"
    },
    {
        "Branch": [
            "Initialize X11 display for if condition"
        ],
        "Loop": [
            "Loop through X11 display for loop condition"
        ],
        "Normal": [
            "DefaultRootWindow for video playback"
        ],
        "FuncName": "X11Renderer_5873 prepareDeviceResource.txt"
    },
    {
        "Branch": [
            "If the video is playing, then the current playback item is set."
        ],
        "Loop": [
            "If the video is looping, then the current playback item is set."
        ],
        "Normal": [
            "Ikona: The current playback item is set."
        ],
        "FuncName": "PlaylistWidget_787 setCurrentPlaying.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "15->16? mpv: This is a conditional video loop",
                    "qDebug() << fmte->fmt: The pixel format is determined by XImage"
                ]
            }
        ],
        "Normal": [],
        "FuncName": "X11Renderer_5873 pixelFormat.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "To rapidly update custom widgets that constantly paint over their entire areas with opaque content like video streaming, it is better to set the widgets to Qt.WA_OpaquePaintEvent, avoiding any unnecessary overhead associated with repainting the widgets' background, similar to how video players handle continuous playback.",
            "setAttribute(Qt.WA_NoSystemBackground);",
            "setAutoFillBackground(false);"
        ],
        "FuncName": "X11Renderer_5873 X11Renderer.txt"
    },
    {
        "Branch": [
            "checks if the X11 renderer supports the specified pixel format, then always returns true and converts to X11 format and scales in receiveFrame() only once, no need to convert format first then scale",
            "pixfmt == d_func().pixfmt && d_func().pixfmt != VideoFormat::Format_Invalid;"
        ],
        "Loop": [],
        "Normal": [
            "enables X11 renderer pixel format support check, if supported, then always returns true and scales in receiveFrame() only once, no need to convert format first then scale",
            "checks if the X11 renderer supports the specified pixel format and scales in receiveFrame() only once, no need to convert format first then scale"
        ],
        "FuncName": "X11Renderer_5873 isSupported.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "\u6211\u4eec\u6307\u5411\u6211\u4eec\u81ea\u5df1\u7684\u6570\u636e\uff0c\u5982\u679cshm\u672a\u4f7f\u7528",
                    "\u9500\u6bc1X11\u56fe\u50cf"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "X11Renderer_5873 destroyX11Image.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "They should be always disconnected in finalize and video playback is paused."
        ],
        "FuncName": "MediaBrowserJS_8277 prepareWidget.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "TODO: fill once each resize? mpv video playback",
            "TODO: set color for video playback",
            "XSetBackground(d.display, d.gc, BlackPixel(d.display, DefaultScreen(d.display))); video background",
            "apply video color"
        ],
        "FuncName": "X11Renderer_5873 drawBackground.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Update device resources when window is displayed. This is a common task for video playback, e.g. recreating render targets for Direct2D or updating video buffers."
        ],
        "FuncName": "X11Renderer_5873 showEvent.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Process video frames in real-time. This may involve decoding, resizing, and encoding video streams to meet the requirements of the video player or other downstream components."
        ],
        "FuncName": "load_xm_4682 ReadXM.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Update texture image data and unlock texture buffer for video playback."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "End video texture update."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "KlakHap_99 TextureUpdateCallback.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "next ximage is ready",
                    "video frame is rendered on the X11 window"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "TODO: interop",
            "-1: image no change",
            "ret<0, frame/vo no change. if host frame, no filters; >0: filters applied on the video frame"
        ],
        "FuncName": "X11Renderer_5873 drawFrame.txt"
    },
    {
        "Branch": [
            "update background when window size changes"
        ],
        "Loop": [],
        "Normal": [
            "update background"
        ],
        "FuncName": "X11Renderer_5873 resizeEvent.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "use native X11 rendering engine for video playback"
        ],
        "FuncName": "X11Renderer_5873 paintEngine.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Adjusting X11 renderer image size for video playback",
            "X11 renderer is 16 aligned for video memory",
            "Setting alignment before mapping video data"
        ],
        "FuncName": "X11Renderer_5873 resizeXImage.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "fill background and display video frames"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "must be set because it will be check isValid somewhere else and video playback is required"
        ],
        "FuncName": "X11Renderer_5873 receiveFrame.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Signals and Slots for video playback control",
            "UI setup for video player"
        ],
        "FuncName": "playercontrols_4087 PlayerControls.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Adding video stream to audio-visual file.",
            "Using codec->time_base is deprecated, but needed for older lavf. (Video codec settings)",
            "Some formats want video stream headers to be separate from audio.",
            "Exposing video encoding context to encoder and setting properties in encoder.",
            "Listing video codecs for a given format in user interface."
        ],
        "FuncName": "AVMuxer_708 addStream.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "/ MUST set after encoder is open to ensure format is valid and the same",
                    "Set avg_frame_rate based on encoder frame_rate for video encoding"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "/ MUST set after encoder is open to ensure format is valid and the same",
                    "need for video encoding"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "AVMuxer_708 prepareStreams.txt"
    },
    {
        "Branch": [
            "If the video stream is interrupted, return true"
        ],
        "Loop": [
            "If the video stream is interrupted, break the loop"
        ],
        "Normal": [
            "Let the demuxer thread run the timer",
            "The video stream is being processed, please wait"
        ],
        "FuncName": "FormatContext_1644 interruptCB.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "If font encoding is unknown, please check the attachment file name extension"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "FormatContext_1644 fixFontsAttachment.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Attachment is used once at open(), data is not used at all. Video playback is enabled by default for this stream."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "FormatContext_1644 selectStreams.txt"
    },
    {
        "Branch": [
            "Checking vec2 default constructor behavior in video code."
        ],
        "Loop": [],
        "Normal": [
            "Error += std::is_trivially_default_constructible<glm::vec2>::value ? 0 : 1; Checking vec2 default initialization in video code.",
            "Error += std::is_trivially_copy_assignable<glm::vec2>::value ? 0 : 1; Checking vec2 copy assignment behavior in video code."
        ],
        "FuncName": "core_type_vec2_7987 test_vec2_ctor.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Workaround for duplicated tags separated by .",
                    "Check only when both tag has the same length and use only letters and numbers for comparision sometimes it differs in  or different/incorrect encoding",
                    "Return the second tag mostly better",
                    "Video tag comparison requires identical length and alphanumeric characters"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "FormatContext_1644 getTag.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Seek to the end of the file, clear buffers, and finish the playback for video"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "FormatContext_1644 seek.txt"
    },
    {
        "Branch": [
            "If-Condition-Str: Supports protocols for video streaming"
        ],
        "Loop": [
            {
                "loopstr": [
                    "Loop-Condition-Str: Registers all input/output formats for video streaming"
                ]
            }
        ],
        "Normal": [
            "Normal-Str: Video streaming protocols supported"
        ],
        "FuncName": "AVMuxer_708 supportedProtocols.txt"
    },
    {
        "Branch": [
            "If-Condition-Str: MUST register all input/output formats for video"
        ],
        "Loop": [
            {
                "loopstr": [
                    "Loop-Condition-Str: MUST register all input/output formats for video in a loop"
                ]
            }
        ],
        "Normal": [
            "Normal-Str: MUST register all input/output formats for video"
        ],
        "FuncName": "AVMuxer_708 supportedExtensions.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " this may block for an indeterminate amount of time",
            "Copy the video sample media times",
            "Copy the video actual data length and the video actual data"
        ],
        "FuncName": "transip_2467 Copy.txt"
    },
    {
        "Branch": [
            "The video must be encoded with one of the following formats: H.264, H.265, VP9, VP8, or AV1."
        ],
        "Loop": [
            {
                "loopstr": [
                    "The video must be registered with all input and output formats.",
                    "The video must be encoded with one of the following formats: H.264, H.265, VP9, VP8, or AV1.",
                    "The video must be registered with all input and output formats and encoded with one of the following formats: H.264, H.265, VP9, VP8, or AV1."
                ]
            }
        ],
        "Normal": [
            "The video must be encoded with one of the following formats: H.264, H.265, VP9, VP8, or AV1."
        ],
        "FuncName": "AVMuxer_708 supportedFormats.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "if we are not part of a graph, then don't indirect the pointer for video decoding",
            "this probably prevents use of the filter without a filtergraph for video processing",
            "Always reconnect the input to account for buffering changes in video streaming",
            "",
            "Because we don't get to suggest a type on ReceiveConnection for video transmission",
            "we need another way of making sure the right type gets used for video encoding.",
            "",
            "One way would be to have our EnumMediaTypes return our output connection type first but more deterministic and simple is to",
            "call ReconnectEx passing the type we want to reconnect with via the base class ReconeectPin method for video reconnection",
            "Reconnect output if necessary for video playback"
        ],
        "FuncName": "transip_2467 CompleteConnect.txt"
    },
    {
        "Branch": [
            "if we are not part of a video graph, then don't indirect the video pointer",
            "this probably prevents use of the video filter without a video filtergraph",
            "Always reconnect the video input to account for video buffering changes"
        ],
        "Loop": [],
        "Normal": [
            "Because we don't get to suggest a video type on ReceiveConnection",
            "we need another way of making sure the right video type gets used.",
            "One way would be to have our EnumMediaTypes return our video output",
            "connection type first but more deterministic and simple is to",
            "call ReconnectEx passing the video type we want to reconnect with",
            "via the base class ReconeectPin method.",
            "Reconnect video output if necessary"
        ],
        "FuncName": "transip_2467 CompleteConnect.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Make sure we have an output allocator for video processing.",
                    "This is a critical step in video rendering."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Must copy so set the allocator properties on the output for video encoding.",
                    "Set the allocator on the output pin for video streaming."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "It's possible that the old and the new are the same thing in video editing.",
                    "AddRef before release ensures that we don't unload the video file.",
                    "We have an allocator for the input pin for video capture."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "If we modify data then don't accept the allocator if it's the same as the output pin's allocator in video processing.",
            "the same as the output pin's allocator",
            "If our output is not connected just accept the allocator for video rendering.",
            "We're never going to use this allocator because when our output pin is connected we'll reconnect this pin for video streaming.",
            "If the allocator is read-only and we're modifying data and the allocator is the same as the output pin's then reject video editing."
        ],
        "FuncName": "transip_2467 NotifyAllocator.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "\u6211\u4eec\u5fc5\u987b\u590d\u5236\u6570\u636e\u3002",
                    "\u590d\u5236\u6570\u636e\u662f\u89c6\u9891\u5904\u7406\u7684\u5173\u952e\u6b65\u9aa4"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "\u4ece\u8f6c\u6362\u4e2d\u8fd4\u56deS_FALSE\u662f\u79c1\u6709\u7684\u534f\u8bae",
                    "\u6211\u4eec\u5e94\u8be5\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u4eceReceive()\u8fd4\u56deNOERROR\uff0c\u56e0\u4e3a",
                    "\u4eceReceive()\u8fd4\u56deS_FALSE\u610f\u5473\u7740\u8fd9\u662f\u6d41\u7684\u672b\u5c3e",
                    "\u4e0d\u5e94\u53d1\u9001\u66f4\u591a\u6570\u636e\u3002",
                    "\u89c6\u9891\u6d41\u5904\u7406\u9700\u8981\u8003\u8651\u534f\u8bae\u548c\u8fd4\u56de\u503c"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "\u68c0\u67e5\u5176\u4ed6\u6d41\u5e76\u5c06\u5176\u4f20\u9012",
            "\u5f00\u59cb\u8ba1\u65f6\u8f6c\u6362InPlace (\u5982\u679c PERF \u5b9a\u4e49)",
            "\u8ba9\u6d3e\u751f\u7c7b\u8f6c\u6362\u6570\u636e",
            "\u505c\u6b62\u65f6\u949f\u5e76\u8bb0\u5f55\u5b83 (\u5982\u679c PERF \u5b9a\u4e49)",
            "\u8f6c\u6362()\u51fd\u6570\u53ef\u4ee5\u8fd4\u56deS_FALSE\u6307\u793a\u4e0d\u5e94\u4ea4\u4ed8\u6837\u672c\uff1b\u6211\u4eec\u53ea\u4ea4\u4ed8\u6837\u672c\uff0c\u5982\u679c\u5b83\u662f\u771f\u7684",
            "S_OK (\u5f53\u7136\uff0c\u4e5f\u662fNOERROR)",
            "\u91ca\u653e\u8f93\u51fa\u7f13\u51b2\u533a\u3002\u5982\u679c\u8fde\u63a5\u7684\u7ba1\u9053\u4ecd\u7136\u9700\u8981\u5b83\uff0c\u5b83\u4f1a\u81ea\u884c addref\u3002",
            "\u91ca\u653e\u8f93\u51fa\u7f13\u51b2\u533a\u3002\u5982\u679c\u8fde\u63a5\u7684\u7ba1\u9053\u4ecd\u7136\u9700\u8981\u5b83\uff0c\u5b83\u4f1a\u81ea\u884c addref\u3002",
            "\u89c6\u9891\u6d41\u5904\u7406\u6d89\u53ca\u6570\u636e\u4f20\u9012\u548c\u7f13\u51b2\u533a\u7ba1\u7406"
        ],
        "FuncName": "transip_2467 Receive.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Preparing video decoder hardware private data from vlc begin",
            "",
            "Preparing video decoder hardware private data from vlc end",
            " TODO: FF_API_GET_BUFFER for video decoding",
            "ffmpeg_GetFrameBuf for video frame buffer management;",
            "ffmpeg_ReleaseFrameBuf for releasing video frame buffer;"
        ],
        "FuncName": "VideoDecoderFFmpegHW_1969 prepare.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Export ass file",
                    "Reload ass file",
                    "Video reload danmaku",
                    "Danmaku reloading with top, bottom, scrolling and reservedArea configurations"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Reserved area for video",
            "Reset disallow mode for video",
            "Convert block words list for video",
            "Reload danmaku for video with top, bottom, scrolling and reservedArea configurations"
        ],
        "FuncName": "mpvObject_8071 reloadDanmaku.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "init mpv_gl with OpenGL frame buffer object of size 1024x768"
        ],
        "FuncName": "mpvObject_8071 createFramebufferObject.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Access settings for video playback",
            "set mpv options for video rendering",
            "We handle video url parsing and decoding",
            "Always play the video when a new file is opened",
            "mpv handles the video volume control",
            "Force to use libmpv for hardware decoding",
            "Configure cache for smoother video playback",
            "Set update callback for video rendering"
        ],
        "FuncName": "mpvObject_8071 MpvObject.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "set referer",
                    "set user-agent",
                    "set proxy",
                    "Some websites do not allow Range option in HTTP request header. To hack these websites, we force FFmpeg/libav to set the stream unseekable. Then we make the video seekable again by enabling seeking in cache."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "set network parameters"
        ],
        "FuncName": "mpvObject_8071 open.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Add Video Tags",
            "Add Video Glossary, Reading, Statistics Header",
            "Add Video Glossary Entries",
            "Add Video Readings",
            "Add Video Onyomi (Chinese)",
            "Add Video Kunyomi (Japanese)",
            "Add Video Statistics",
            "Add Video Everything Else"
        ],
        "FuncName": "kanjiwidget_8050 buildDefinitionLabel.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " Clear list and cancel all network actions. Update interface and settings when media browser provider changes."
        ],
        "FuncName": "MediaBrowser_4886 providerChanged.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Load audio track and adjust video settings for MPV playback",
                    "Load danmaku and enable subtitles for MPV"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "It's double in MPV player, check video resolution and frame rate"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "It's double in MPV player, check video resolution and frame rate"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "mpvObject_8071 onMpvEvent.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Allocate buffer for video processing",
            "FIXME: not sure what video size to use",
            "Video processing details can be found in destructor",
            "Allocate AVIOContext for video I/O"
        ],
        "FuncName": "decoderiocontext_6344 DecoderIOContext.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "return the file size if you wish to"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "find the location of the file in the video"
        ],
        "FuncName": "decoderiocontext_6344 IOSeekFunc.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Let FFmpeg know that we have reached EOF or do something else, this is a video processing condition"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "decoderiocontext_6344 IOReadFunc.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " you can specify a format directly, such as h264 for video encoding",
            " pCtx->iformat = av_find_input_format('h264');",
            " or read some of the file and let ffmpeg do the guessing, which is useful for video files",
            " reset to beginning of file, where video playback starts"
        ],
        "FuncName": "decoderiocontext_6344 initAVFormatContext.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "TODO: handle duplicates and remove sprites from the SpriteList"
        ],
        "FuncName": "Compositor_4277 RemoveSprites.txt"
    },
    {
        "Branch": [
            "Check if video is playing"
        ],
        "Loop": [
            "Loop through video frames"
        ],
        "Normal": [
            "TODO: handle video duplicates"
        ],
        "FuncName": "Compositor_4277 AddSprites.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "additional 15 bytes to ensure 16 bytes aligned",
                    "plane 1, 2... is aligned",
                    "This is a video frame copy operation, where the frame is copied to a new frame."
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "set chroma address and pitch if not set",
                    "This is a loop condition that sets the chroma address and pitch if they are not already set."
                ]
            },
            {
                "loopstr": [
                    "TODO: add VideoFormat::planeWidth/Height",
                    "pitch instead of surface_width",
                    "This is a loop condition that adds the video format plane width and height, and uses pitch instead of surface width."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "VideoDecoderFFmpegHW_1969 copyToFrame.txt"
    },
    {
        "Branch": [
            "If the video is playing, press the pause button to pause it."
        ],
        "Loop": [
            "If the video is on loop, press the loop button to turn it off."
        ],
        "Normal": [
            "vSpacer",
            "Press the play button to start playing the video.",
            "Use the seek bar to fast forward or rewind the video.",
            "You can adjust the video quality by clicking on the settings icon."
        ],
        "FuncName": "AddressDialog_3318 AddressDialog.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "quadBatch = std::make_shared<QuadBatch>(1920, 1080); rendering a 1920x1080 video"
        ],
        "FuncName": "Compositor_4277 Compositor.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "The first three bytes are the length of the section (not including the header) or zero if using an eight-byte header",
            "The fourth byte stores the section type, typically indicating a video codec or compression method, such as H.264 or MPEG-4 AVC"
        ],
        "FuncName": "hap_8403 hap_write_section_header.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "Assume snappy compression, worst-case scenario for video encoding"
                ]
            }
        ],
        "Normal": [
            "Start with the length of a multiple image section header in video coding",
            "Return 0 for invalid video encoding arguments"
        ],
        "FuncName": "hap_8403 HapMaxEncodedLength.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "This is a hard limit due to the 4-byte headers we use for the decode instruction container and video encoding requirements.",
            " (0xFFFFFF == count + (4 x count) + 20) with video frame encoding considerations",
            "Divide frame equally on DXT block boundaries (8 or 16 bytes) for efficient video compression"
        ],
        "FuncName": "hap_8403 hap_limited_chunk_count_for_frame.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "top section header + decode instructions section header + decode instructions + compressed data + HAP encoding"
        ],
        "FuncName": "hap_8403 hap_max_encoded_length.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    " We attempt to chunk as requested, and if resulting frame is larger than it is uncompressed then store frame uncompressed ",
                    " Check we have space for the Decode Instructions Container",
                    " write the Decode Instructions section header",
                    " write the Second Stage Compressor Table section header",
                    " write the Chunk Size Table section header",
                    " This is a specific scenario for HAP format video encoding"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " store the chunk uncompressed",
                    " This is a specific scenario for HAP format video encoding"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " use the complex storage because snappy compression saved space",
                    " This is a specific scenario for HAP format video encoding"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            " Check arguments ",
            " To store frames of length greater than can be expressed in three bytes, we use an eight byte header (the last four bytes are the frame size). We don't know the compressed size until we have performed compression, but we know the worst-case size (the uncompressed size), so choose header-length based on that. A simpler encoder could always use the eight-byte header variation.",
            " HAP format video encoding requires careful consideration of frame sizes and compression"
        ],
        "FuncName": "hap_8403 hap_encode_texture.txt"
    },
    {
        "Branch": [
            {
                "thenstr": "Encode without the multi-image layout",
                "elsestr": []
            },
            {
                "thenstr": "Permitted combinations: HapTextureFormat_YCoCg_DXT5 + HapTextureFormat_A_RGTC1",
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "hap_8403 HapEncode.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Check the last error message of the session bus.",
                    "Check if the interface is valid and print the path and property."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Create a QDBusInterface object.",
            "Get the property value, which is not used."
        ],
        "FuncName": "dbusutils_1961 redDBusProperty.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    " Verify buffer is big enough to contain an eight-byte video header "
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            " Verify buffer is big enough to contain a four-byte video header ",
            " The first three bytes are the length of the video section not including the header or zero if the length is stored in the last four bytes of an eight-byte video header ",
            " If the first three bytes are zero the size is in the following four bytes ",
            " The fourth byte stores the video section type ",
            " Verify the video section does not extend beyond the buffer "
        ],
        "FuncName": "hap_8403 hap_read_section_header.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "qInfo() << error << qPrintable(QDBusConnection::sessionBus().lastError().message())",
                    "This line is related to the video type and indicates an error condition."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "return reply.value()",
                    "This line is related to the video type and indicates a successful value retrieval."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Creating a QDBusInterface interface",
            "Calling the remote value method",
            "This is a normal string related to video type and describes the process of creating a QDBusInterface interface and calling the remote value method."
        ],
        "FuncName": "dbusutils_1961 redDBusMethod.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " TODO: use factory.registedNames() and the order, and this is a video subtitle with a specific description for the video type"
        ],
        "FuncName": "Subtitle_1853 Subtitle.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Step through, counting video frames"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "hap_8403 HapGetFrameTextureCount.txt"
    },
    {
        "Branch": [
            "Conditions under which the subtitle suffixes are applied to the video"
        ],
        "Loop": [
            "Conditions under which the subtitle suffixes are applied to the video"
        ],
        "Normal": [
            "if (priv->suffixes.isEmpty())",
            "    return supportedSuffixes();",
            "Subtitle suffixes are applied to the video when the suffixes are not empty."
        ],
        "FuncName": "Subtitle_1853 suffixes.txt"
    },
    {
        "Branch": [
            "If the video decoder is registered, then proceed"
        ],
        "Loop": [
            "Loop through the registered video decoders"
        ],
        "Normal": [
            "factory.h does not check whether an id is registered",
            "The video decoder is registered with a unique id"
        ],
        "FuncName": "VideoDecoder_5273 VideoDecoder_RegisterAll.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Step through until we find the section at index ",
                    "This is a video frame with a single texture as the top section."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "A single-texture frame with the texture as the top section. ",
                    "This is a video frame with a single texture as the top section."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "hap_8403 hap_get_section_at_index.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Video cannot be processed in this condition, not thread safe.",
            "Release video processors not required",
            "Video DO NOT set privilege suffixes",
            "It's safe to reload video"
        ],
        "FuncName": "Subtitle_1853 setEngines.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Decode the located texture",
                    "This is a step in video decoding, specifically for Hap encoded images."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Check arguments",
            "Locate the section at the given index, which will either be the top-level section in a single texture image, or one of the sections inside a multi-image top-level section.",
            "This step is crucial for video processing, especially when dealing with Hap encoded images."
        ],
        "FuncName": "hap_8403 HapDecode.txt"
    },
    {
        "Branch": [
            "video condition: if statement"
        ],
        "Loop": [
            "video condition: loop statement"
        ],
        "Normal": [
            "compare the whole content is not a good idea, video analysis: content comparison"
        ],
        "FuncName": "Subtitle_1853 setRawData.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "The top-level section contains a Decode Instructions Container followed by frame data related to video compression and decompression.",
                    "Frame data follows immediately after the Decode Instructions Container, which is essential for video playback.",
                    "Step through the sections inside the Decode Instructions Container to understand video decoding instructions.",
                    "The Chunk Second-Stage Compressor Table and Chunk Size Table are required for video decompression and data storage."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Step through the chunks, storing information for their decompression and video playback."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Perform decompression and video playback, checking for any errors that may have occurred during the process."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "We don't invoke the callback for one chunk, just decode it directly and focus on video decoding."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Only one section is present containing a single block of snappy-compressed texture data, which is crucial for video texture rendering."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Only one section is present containing a single block of uncompressed texture data, which is essential for video texture rendering."
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "If we calculated a chunk count and already have one, make sure they match for accurate video chunking and decompression."
                ]
            }
        ],
        "Normal": [
            "One top-level section type describes texture-format and second-stage compression Hap compressor/format constants, which can be unpacked by reading the top and bottom four bits related to video compression.",
            "Pass the texture format out for video rendering and playback.",
            "Fill out the remaining return value with video-related information."
        ],
        "FuncName": "hap_8403 hap_decode_single_texture.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "TODO: detect image change, timestamped subtitles for video content"
        ],
        "FuncName": "Subtitle_1853 setTimestamp.txt"
    },
    {
        "Branch": [
            " Conditional statement to check if a video is playing or not."
        ],
        "Loop": [
            " Looping through each frame of the video to extract subtitles."
        ],
        "Normal": [
            " TODO: store bounding rect here and not in processor. This string is related to video processing and bounding rectangle calculation."
        ],
        "FuncName": "Subtitle_1853 getSubImages.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "TODO: if seek to previous position, an invalid frame is returned. This is a common issue in video playback.",
            "usually add to the end. TODO: test video playback functionality."
        ],
        "FuncName": "Subtitle_1853 processLine.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "always render the image to support animations, which is a crucial aspect of video rendering",
            "TODO: store bounding rect here and not in processor, optimizing video processing"
        ],
        "FuncName": "Subtitle_1853 getImage.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "if (priv->suffixes.isEmpty()) returns a list of supported video file suffixes",
            "returns a list of supported video file suffixes"
        ],
        "FuncName": "Subtitle_1853 suffixes.txt"
    },
    {
        "Branch": [
            "Video Condition: If-Condition-Str",
            "Subtitle Processor: If-Condition-Str"
        ],
        "Loop": [
            "Video Condition: Loop-Condition-Str",
            "Subtitle Processor: Loop-Condition-Str"
        ],
        "Normal": [
            "Video Code: Normal-Str",
            "Subtitle Processor: Normal-Str"
        ],
        "FuncName": "Subtitle_1853 processHeader.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "\u9700\u8981qt\u7f51\u7edc\u6a21\u5757\u7f51\u7edc",
                    "\u89c6\u9891\u5b57\u5e55\u52a0\u8f7d\u9700\u8981\u7f51\u7edc\u8fde\u63a5"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "\u901a\u77e5\u7528\u6237\u66f4\u65b0\u5b57\u5e55",
            "\u9501\u4e0d\u9700\u8981\u56e0\u4e3a\u5b83\u73b0\u5728\u6ca1\u6709\u52a0\u8f7d",
            "\u539f\u59cb\u6570\u636e\u8bbe\u7f6e\uff0c\u6587\u4ef6\u540d\u548cURL\u4e3a\u7a7a",
            "\u4eceURL\u8bfb\u53d6\u89c6\u9891\u5b57\u5e55",
            "\u4ece\u6587\u4ef6\u8bfb\u53d6\u89c6\u9891\u5b57\u5e55"
        ],
        "FuncName": "Subtitle_1853 load.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "for old video configuration data migration to new location"
        ],
        "FuncName": "Config_3311 moveOldCfg.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " TODO: why crash on mac qt5.4 if call on aboutToQuit() when playing a video"
        ],
        "FuncName": "Config_3311 save.txt"
    },
    {
        "Branch": [
            "Add task to download manager if condition is met"
        ],
        "Loop": [
            "Add task to download manager in loop"
        ],
        "Normal": [
            "Show message for video download"
        ],
        "FuncName": "downloader_7500 addTasks.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "When RTT is not used, the video dock has a native window."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "OpenGLWriter_6134 OpenGLWriter.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Open video decoder to decode video stream.",
                    "Detect video stream type and check if the decoder supports it.",
                    "Choose a suitable decoder and decoding method based on the video stream type and decoder support.",
                    "Use QMPlay2 Vulkan deinterlacing to workaround an Intel Media Driver bug",
                    "https://github.com/intel/media-driver/issues/804"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "FFDecVAAPI_1295 open.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "f->channels = fmt.channels(); //remove? not available in libav9",
                    "must be (not the last frame) exactly frame_size unless CODEC_CAP_VARIABLE_FRAME_SIZE is set (frame_size==0)",
                    "TODO: mpv use pcmhack for avctx.frame_size==0. can we use input frame.samplesPerChannel?",
                    "/f->quality = d.avctx->global_quality; //TODO",
                    "TODO: record last pts. mpv compute pts internally and also use playback time",
                    "pts is set in muxer",
                    "bytes between 2 samples on a plane. TODO: add to AudioFormat? what about bytesPerFrame?",
                    "Audio encoding for video frames"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "qWarning(error avcodec_encode_audio2: %s,av_err2str(ret));",
                    "av_packet_unref(&pkt); //FIXME",
                    "false",
                    "Error encoding audio frame"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "invalid frame means eof",
                    "End of video frame"
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "frame.bytesPerLine(i); //",
                    "Looping through video frames"
                ]
            }
        ],
        "Normal": [
            "NULL",
            "0",
            "qDebug(enc avpkt.pts: %lld, dts: %lld., pkt.pts, pkt.dts);",
            "qDebug(enc packet.pts: %.3f, dts: %.3f., d.packet.pts, d.packet.dts);",
            "Video encoding and debugging"
        ],
        "FuncName": "AudioEncoderFFmpeg_7288 encode.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "LOGI(IDemux Read %d:,data.size); Video demuxing in progress..."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "IDemux_3037 Main.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Set video size according to screen size",
            "Is another task running?"
        ],
        "FuncName": "danmakuLoader_538 start.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "load settings",
                    "Font",
                    "Font size",
                    "Duration of comment display",
                    "Duration of still danmaku",
                    "text opacity",
                    "Create parser",
                    "Convert",
                    "Parse XML file and extract video metadata"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "danmakuLoader_538 onXmlDownloaded.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Qt seems has a bug that will not be encoded as in url query for video files"
        ],
        "FuncName": "online_sub_5315 hash_file.txt"
    },
    {
        "Branch": [
            "Clear history, send historyChanged signal for If-Condition video"
        ],
        "Loop": [
            "Clear history, send historyChanged signal for Loop-Condition video"
        ],
        "Normal": [
            "'TRUNCATE table history' is faster for video playback"
        ],
        "FuncName": "Config_3311 clearHistory.txt"
    },
    {
        "Branch": [
            "Save conditional configuration data for video playback.",
            "Conditional video playback configuration data saved."
        ],
        "Loop": [
            "Save loop condition configuration data for video playback.",
            "Loop condition video playback configuration data saved."
        ],
        "Normal": [
            " TODO: why crash on mac qt5.4 if call on aboutToQuit(): Saved configuration data for video playback."
        ],
        "FuncName": "Config_3311 save.txt"
    },
    {
        "Branch": [
            "Download subtitles and clean cache after completion"
        ],
        "Loop": [
            {
                "loopstr": [
                    "Filter out some index files (idx) related to video content"
                ]
            }
        ],
        "Normal": [
            "Video content processing and optimization"
        ],
        "FuncName": "online_sub_5315 subtitlesDownloadComplete.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "HW is ignored",
            "video decoding",
            "video decoder optimization",
            "d3d11 performance issue due to gltexsubimage2d"
        ],
        "FuncName": "Config_3311 reload.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "This must be in a separate condition w/o assigning condition to a variable, otherwise the compiler will not optimize it.",
                    "otherwise the compiler will not optimize it. This statement is related to video playback, ensuring smooth and optimal video quality."
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "thenstr": [
                    "This loop condition is related to video playback, ensuring consistent loop duration and efficient resource utilization.",
                    "video playback, ensuring consistent loop duration and efficient resource utilization."
                ],
                "elsestr": []
            }
        ],
        "Normal": [
            {
                "thenstr": [
                    "This statement is related to video playback, ensuring high-quality video rendering and efficient memory management.",
                    "video playback, ensuring high-quality video rendering and efficient memory management."
                ],
                "elsestr": []
            }
        ],
        "FuncName": "YadifDeint_6786 check.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "Downloading subtitles from URL: ",
                    "QUrl url(sub.link.toUtf8());",
                    "qInfo() << __func__ << sub.link << url;",
                    "Subtitle downloading process initiated."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "online_sub_5315 downloadSubtitles.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "q.addQueryItem(pathinfo, fi.absoluteFilePath()); Video file path added to query.",
            "q.addQueryItem(lang, chn); Language and character set added to query.",
            "qInfo() << req_url << params.query(QUrl::FullyEncoded); Request URL and query parameters logged."
        ],
        "FuncName": "online_sub_5315 requestSubtitle.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "DO NOT call save() in dtor because it's a singleton and may be deleted later than qApp, QFont is not valid. This is related to video playback, where the font is used to display video captions.",
            "FIXME: what if qapp not ready for video playback"
        ],
        "FuncName": "Config_3311 Config.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    " fix bug 24817 by ZhuYuliang. This is a video fix."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "set name to disposition filename. This is a video filename."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "reply->deleteLater(); This code is related to video playback."
        ],
        "FuncName": "online_sub_5315 replyReceived.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    " Reads 3 pixels to the left/right for video processing ",
                    " Spatial interlacing check for video frame analysis "
                ]
            }
        ],
        "Normal": [],
        "FuncName": "YadifDeint_6786 filterLine.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "synchronizing video frames",
                    "sync"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "FrameReader_5872 readMore.txt"
    },
    {
        "Branch": [
            "Pass if condition to the video player and handle the event accordingly"
        ],
        "Loop": [
            "Pass loop condition to the video player and update the video playback"
        ],
        "Normal": [
            "Pass gesture and touch event to the video player and handle the event accordingly"
        ],
        "FuncName": "XVideoWriter_239 event.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "new source frame"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "FrameReader_5872 tryLoad.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "qDebug(\"demuxer read error\"); Video error occurred during demuxer read."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "qDebug(\"not video stream\"); Video stream not found."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "qDebug(\"frame got @%.3f, queue enough: %d, frame.timestamp(), vframes.isEnough()\"); Video frame received at %.3f seconds, queue has enough frames: %d."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "make sure take() will not be blocked Video frame processing is ongoing to prevent take() blocking."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "TODO: decode eof packets Decode end of file packets for video stream."
        ],
        "FuncName": "FrameReader_5872 readMoreInternal.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Opens XAudio2 audio output device. Device ID property is required.",
                    "Parameters now default to specific values."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "XAUDIO2_DEVICE_DETAILS details;",
            "sizeof(wf)",
            "dwChannelMask",
            "Channel count must be 2 or less, refer to DirectSound documentation.",
            "XAUDIO2_VOICE_NOSRC | XAUDIO2_VOICE_NOPITCH;",
            "Sample frequency is fixed at 1.0 MHz."
        ],
        "FuncName": "AudioOutputXAudio2_6862 open.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "No return because decoder needs more packets before the desired frame is decoded. This is a common issue when dealing with video decoding, where the decoder requires a certain number of packets to decode a frame."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "TODO: flag forward: result pts must >= value. This is an optimization flag that can be used to improve video decoding performance."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "FIXME: Internal error. Can not be a key frame!!!!. This is a critical error that indicates a problem with the video decoding process. The decoder is unable to decode a key frame, which is a fundamental component of video decoding.",
                    "return false; //?? This line is likely a temporary fix or a placeholder for further development."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "qDebug(VideoFrameExtractor: invalid frame!!!);. This message indicates that the video frame extractor has encountered an invalid frame, which can cause issues with video decoding."
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "qDebug(video packet: %f, pkt.pts);. This message logs the video packet and its presentation timestamp.",
                    "TODO: always key frame?. This is an optimization flag that can be used to improve video decoding performance by always seeking to key frames."
                ]
            },
            {
                "loopstr": [
                    "qWarning(invalid key frame!!!!! undecoded: %d, decoder->undecodedSize());. This message warns that an invalid key frame has been encountered, which can cause issues with video decoding."
                ]
            },
            {
                "loopstr": [
                    "qDebug(video packet: %f, delta=%lld, t, value - qint64(t*1000.0));. This message logs the video packet and its timestamp, as well as the delta between the current and previous timestamps.",
                    "invalid packet?. This message suggests that the video packet may be invalid or corrupted, which can cause issues with video decoding.",
                    "store the last decoded frame because next frame may be out of range. This is a temporary fix to store the last decoded frame in case the next frame is out of range.",
                    "",
                    "if decoder was not flushed, we may get old frame which is acceptable. This message suggests that if the decoder has not been flushed, it may return an old frame, which can be acceptable in certain situations."
                ]
            }
        ],
        "Normal": [
            "enlarge range if seek to key-frame failed. This is a common issue when dealing with video decoding, where seeking to a key frame fails and the range needs to be enlarged.",
            "must flush otherwise old frames will be decoded at the beginning. This message emphasizes the importance of flushing the decoder to ensure that old frames are not decoded at the beginning.",
            "must decode key frame. This is a fundamental component of video decoding, where the key frame needs to be decoded to ensure proper video playback.",
            "if seek backward correctly to key frame, diff0 = t - value <= 0. This is a condition that checks if seeking backward to a key frame is successful, and the difference between the current and previous timestamps is less than or equal to 0.",
            "but sometimes seek to no-key frame(and range is enlarged), diff0 >= 0. This message suggests that sometimes seeking to a non-key frame (and enlarging the range) can result in a difference between the current and previous timestamps being greater than or equal to 0.",
            "decode key frame. This is a fundamental component of video decoding, where the key frame needs to be decoded to ensure proper video playback.",
            "0: default, 1: framedrop. This message suggests that there are two options for video decoding: default (0) or framedrop (1).",
            "decode at the given position. This message emphasizes the importance of decoding the video at the given position to ensure proper video playback."
        ],
        "FuncName": "FrameReader_5872 seekInternal.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "master or source video"
        ],
        "FuncName": "AudioOutputXAudio2_6862 setVolume.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "makeCurrent(); // Initialize OpenGL environment.",
            "qt4 returns const // Related to video rendering."
        ],
        "FuncName": "OpenGLRendererBase_4738 onInitializeGL.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Update the video rendering pipeline by recreating the render target for Direct2D. When the window stays on top hint changes, the window will initially hide and then show. This ensures the widget content is updated accordingly."
        ],
        "FuncName": "OpenGLRendererBase_4738 onShowEvent.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " we can mix gl and qpainter.  QPainter painter(this);  painter.beginNativePainting();  gl functions handle video rendering.  painter.endNativePainting();  swapBuffers(); ",
            "context()->swapBuffers(this); video buffer updated."
        ],
        "FuncName": "OpenGLRendererBase_4738 onPaintGL.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Z axis with OpenGL rendering ratio"
        ],
        "FuncName": "OpenGLRendererBase_4738 setupAspectRatio.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "d.glv.render(QRectF(-1, 1, 2, -2), roi, d.matrix); Renders a frame of the OpenGL renderer.",
            " QRectF() means the whole viewport of the OpenGL renderer."
        ],
        "FuncName": "OpenGLRendererBase_4738 drawFrame.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "mat4(\n",
            "\t// Define a 4x4 matrix with 4 rows and 4 columns\n",
            "\tvec4(%.9f, %.9f, %.9f, %.9f)\n",
            "\tvec4(%.9f, %.9f, %.9f, %.9f)\n",
            "\tvec4(%.9f, %.9f, %.9f, %.9f)\n",
            "\tvec4(%.9f, %.9f, %.9f, %.9f))\n\n"
        ],
        "FuncName": "core_type_mat4x4_831 print.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Error += std::is_trivially_default_constructible<glm::mat4>::value ? 0 : 1;",
            "Error += std::is_trivially_copy_assignable<glm::mat4>::value ? 0 : 1;",
            "Error += std::is_copy_constructible<glm::mat4>::value ? 0 : 1;",
            "Error += std::has_trivial_copy_constructor<glm::mat4>::value ? 0 : 1;",
            "This line tests the properties of glm::mat4, checking for trivial copyability and default constructibility in video game development."
        ],
        "FuncName": "core_type_mat4x4_831 test_ctr.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Receiving video frames and updating the user interface in a video thread."
        ],
        "FuncName": "OpenGLRendererBase_4738 receiveFrame.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "QOpenGLWindow::resizeEvent(e); //will call resizeGL(). TODO:will call paintEvent()"
        ],
        "FuncName": "OpenGLRendererBase_4738 onResizeEvent.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "sets the size and content of the surface, required for video processing with videotoolbox, used for map and CVPixelBufferRelease"
        ],
        "FuncName": "SurfaceInteropCV_5901 setSurface.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Display video playback overlay. Determine how this method should work by checking OSC video visibility and control video playback.",
            "Restart the video timer and continue playback."
        ],
        "FuncName": "playeroverlay_4656 showOverlay.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "TODO: integrate video surface resource"
        ],
        "FuncName": "SurfaceInteropCV_5901 unmap.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "get address results in internal copy, video frame processing involves mapping video format to native format and storing it in host memory"
                ]
            }
        ],
        "Normal": [
            "CVPixelBufferRelease(cv_buffer); // release when video frame is destroyed, video frame is then garbage collected by the system"
        ],
        "FuncName": "SurfaceInteropCV_5901 mapToHost.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "NOTE: ensure Config::instance().reset() is called before it. It is called in ConfigDialog.reset() and related to video playback settings."
        ],
        "FuncName": "ConfigPageBase_4564 reset.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "DO NOT call setMediaStatus() here. This may cause demuxer to be closed in another thread.",
                    "MUST make sure blocking functions (open, read) return before we change the status because demuxer may be closed in another thread at the same time if status is not LoadingMedia, use handleError() after blocking functions return is good.",
                    "1: blocking operation will be aborted due to video processing timeout.",
                    "interrupt video playback"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "qDebug(timer is not valid, start it); reset video timer.",
                    "handler->mLastTime = handler->mTimer.elapsed(); update video timer elapsed time."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "maybe changed in other threads, video status may be updated.",
                    "handler->mStatus.testAndSetAcquire(0, ec); update video status with error code."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "FIXME: maybe changed in other threads, video status may be updated."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "check manual interruption of video playback.",
            "qApp->processEvents(); //FIXME: qml crash when video playback is interrupted.",
            "use restart video playback from beginning.",
            "emit demuxer error and handle error during video playback."
        ],
        "FuncName": "AVDemuxer_2751 handleTimeout.txt"
    },
    {
        "Branch": [
            "If the video is playing, then..."
        ],
        "Loop": [
            "Loop the video until..."
        ],
        "Normal": [
            "Determine how this method should work by checking OSC visibility and displaying video playback controls."
        ],
        "FuncName": "playeroverlay_4656 hideOverlay.txt"
    },
    {
        "Branch": [
            "Update data for if condition observers.",
            "Update data for if condition observers."
        ],
        "Loop": [
            "Update data for loop condition observers.",
            "Update data for loop condition observers."
        ],
        "Normal": [
            "Lock mutex for normal operation.",
            "Unlock mutex for normal operation."
        ],
        "FuncName": "IObserver_479 notify.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "mutex.lock(); synchronization lock acquired",
            "mutex.unlock(); synchronization lock released"
        ],
        "FuncName": "IObserver_479 AddOberver.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "check network protocol using URLContext.flags == URL_PROTOCOL_FLAG_NETWORK and set network flags for video streaming",
            "video network concat cache pipe avdevice crypto"
        ],
        "FuncName": "AVDemuxer_2751 checkNetwork.txt"
    },
    {
        "Branch": [
            " if (dst.isSet()) { "
        ],
        "Loop": [
            " while (dst.hasNext()) { "
        ],
        "Normal": [
            " why not dst.constData() is used in video processing? "
        ],
        "FuncName": "OpenGLTypes_929 set_uniform_value.txt"
    },
    {
        "Branch": [
            "If the condition is true, then the video will play."
        ],
        "Loop": [
            "The loop will continue until the video is finished."
        ],
        "Normal": [
            "why not dst.constData()? The video data is not being used."
        ],
        "FuncName": "OpenGLTypes_929 set_uniform_value.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "or simply set s to streamValue if value is contained in streams?",
                    "streamValue -1 is ok",
                    "Video decoding formats: H.264, H.265, VP9"
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "MUST register all input/output formats",
                    "Video decoding formats: H.264, H.265, VP9"
                ]
            }
        ],
        "Normal": [
            "if (!streams->contains(si->stream)) {",
            "qWarning(%d is not a valid stream for stream type %d, si->stream, st);",
            "return false;",
            "}",
            "don't touch wanted index",
            "Video decoding formats: H.264, H.265, VP9"
        ],
        "FuncName": "AVDemuxer_2751 supportedFormats.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " io.seekable: byte seeking, applicable in video streaming",
            " format.read_seek: time seeking, used in video streaming for example HLS, seeking on HLS stream steps: find segment, read packet in segment and drop until desired pts got"
        ],
        "FuncName": "AVDemuxer_2751 checkSeekable.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "TODO: xxx_register_all already use static var"
        ],
        "FuncName": "AVDemuxer_2751 AVDemuxer.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "DO NOT use d->history.last-first. Video frames are displayed at a rate of 24 frames per second.",
            "dt should be always > 0 because history stores absolute time. Video playback is smooth and continuous."
        ],
        "FuncName": "Statistics_6313 currentDisplayFPS.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " We should never fall out of the switch above unless theres an error. This is a video related statement that describes the outcome of a video processing operation. "
        ],
        "FuncName": "http_parser_2376 parse_url_char.txt"
    },
    {
        "Branch": [
            "Conditional rendering of video frames based on uniform variables, such as texture coordinates, viewports, and projection matrices."
        ],
        "Loop": [
            "Iterative processing of video frames based on uniform variables, such as texture coordinates, viewports, and projection matrices."
        ],
        "Normal": [
            "Uniform variables in GLSL shaders, including highp and lowp precision types, used for video rendering and processing."
        ],
        "FuncName": "OpenGLTypes_929 ParseUniforms.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Users should only be pausing/unpausing a parser that is not in an error state. In non-debug builds, there's not much that we can do about this other than ignore it. This is related to video playback and should be considered as a video pause functionality."
        ],
        "FuncName": "http_parser_2376 http_parser_pause.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    " HTTP/1.1 ",
                    " Video streaming active: true "
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "http_parser_2376 http_should_keep_alive.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "See RFC 2616 section 4.4"
        ],
        "FuncName": "http_parser_2376 http_message_needs_eof.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Audio parameters has been changed. This change affects video playback.",
                    "Wait for audioParamsUpdate() to be finished before proceeding."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Don't play video if it is not ready. Audio parameters will be updated later."
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "Audio playback position is independent of video seek position."
                ]
            },
            {
                "loopstr": [
                    "Audio timestamp estimation is used."
                ]
            },
            {
                "loopstr": [
                    "TODO: Add options for audio playback."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "AudioThr_2077 run.txt"
    },
    {
        "Branch": [
            "Compare HTTP host with video code"
        ],
        "Loop": [],
        "Normal": [
            " Ensure video playback continuity"
        ],
        "FuncName": "http_parser_2376 http_parse_host.txt"
    },
    {
        "Branch": [
            "Initialize HTTP parser for video playback"
        ],
        "Loop": [],
        "Normal": [
            "Preserve application data for video streaming"
        ],
        "FuncName": "http_parser_2376 http_parser_init.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    " nada ",
                    " related to HTTP PROPPATCH method"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " or HTTP_PROPPATCH ",
                    " related to HTTP PROPPATCH method"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " or HTTP_PURGE ",
                    " related to HTTP PURGE method"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " they might be just sending \n instead of \r\n so this would be  the second \n to denote the end of headers",
                    " related to HTTP header parsing"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " looking for 'Connection: close' ",
                    " related to HTTP Connection header"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " looking for 'Connection: close' ",
                    " related to HTTP Connection header"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " Skip lws ",
                    " related to HTTP whitespace handling"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " End of a chunked request ",
                    " related to HTTP chunked encoding"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " Exit, the rest of the message is in a different protocol. ",
                    " related to HTTP protocol switching"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " chunked encoding - ignore Content-Length header ",
                    " related to HTTP Content-Length header and chunked encoding"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " Content-Length header given but zero: Content-Length: 0\r\n ",
                    " related to HTTP Content-Length header"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " Content-Length header given and non-zero ",
                    " related to HTTP Content-Length header"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " Assume content-length 0 - read the next ",
                    " related to HTTP Content-Length header"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " Mimic CALLBACK_DATA_NOADVANCE() but with one extra byte.  The alternative to doing this is to wait for the next byte to  trigger the data callback, just as in every other case. The  problem with this is that this makes it difficult for the test  harness to distinguish between complete-on-EOF and  complete-on-length. It's not clear that this distinction is  important for applications, but let's keep it for now. ",
                    " related to HTTP callback handling"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    " Exit, the rest of the message is in a different protocol. ",
                    " related to HTTP protocol switching"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            " We're in an error state. Don't bother doing anything. ",
            " Run callbacks for any marks that we have leftover after we ran our of  bytes. There should be at most one of these set, so it's OK to invoke  them in series (unset marks will not result in callbacks).  We use the NOADVANCE() variety of callbacks here because 'p' has already  overflowed 'data' and this allows us to correct for the off-by-one that  we'd otherwise have (since CALLBACK_DATA() is meant to be run with a 'p'  value that's in-bounds). "
        ],
        "FuncName": "http_parser_2376 http_parser_execute.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "initialize something. e.g. environment check. Video: This is a video describing the environment check process."
        ],
        "FuncName": "Logger_9763 warning.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "video suffix has only 1 dot, typically indicating a single file or a specific video format"
        ],
        "FuncName": "AVFilterSubtitle_6661 findAndSetFile.txt"
    },
    {
        "Branch": [
            "check if video playback is enabled"
        ],
        "Loop": [
            "loop through video frames"
        ],
        "Normal": [
            "initialize video player and load video file",
            "check video playback settings and adjust accordingly",
            "display video playback controls"
        ],
        "FuncName": "Logger_9763 critical.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "connect(player, SIGNAL(fileChanged(QString)), SLOT(findAndSetFile(QString)))",
                    "AVPlayer supports subtitles, allowing users to display text overlays on top of the video."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "AVFilterSubtitle_6661 setPlayer.txt"
    },
    {
        "Branch": [
            "connect(this, SIGNAL(statusChanged()), SLOT(onStatusChanged())) - This line is related to video status change event handling."
        ],
        "Loop": [
            "connect(this, SIGNAL(statusChanged()), SLOT(onStatusChanged())) - This line is related to video status change event handling."
        ],
        "Normal": [
            "connect(this, SIGNAL(statusChanged()), SLOT(onStatusChanged())) - This line is related to video status change event handling."
        ],
        "FuncName": "AVFilterSubtitle_6661 AVFilterSubtitle.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Prints the current message and repeats the message to avoid duplicate logs in video processing."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Repeats the check process in video processing.",
            "qt_message_output is a public API used for video-related log output."
        ],
        "FuncName": "Logger_9763 log_helper.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "initialize something. e.g. environment check, such as checking the video codec and resolution",
            "cannot use ctx.debug() because QT_NO_DEBUG_STREAM may be defined, which can affect video playback"
        ],
        "FuncName": "Logger_9763 debug.txt"
    },
    {
        "Branch": [
            "If the video player is not initialized, a warning log will be issued."
        ],
        "Loop": [
            "The video player will loop continuously until stopped."
        ],
        "Normal": [
            " initialize something. e.g. environment check"
        ],
        "FuncName": "Logger_9763 warning.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "DO NOT return here because option is null now. This is a video-related instruction."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "filter_name=argument. use ' to quote the argument, use \\ to escaping chars within quoted text. on windows, path can be C:/a/b/c, \\:\\ must be escaped. This is a video processing filter."
        ],
        "FuncName": "AVFilterSubtitle_6661 setFile.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "initialize something. e.g. environment check",
            "can not use ctx.debug() because QT_NO_DEBUG_STREAM maybe defined",
            "Video-Related-Description: The video code requires a debug level log to be set for proper execution."
        ],
        "FuncName": "Logger_9763 debug.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "From Monogame with 3D video capabilities, utilizing a perspective projection matrix to create a sense of depth and distance."
        ],
        "FuncName": "Matrix4_5867 CreateOrthographicOffCenter.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "pointed to qimage data and utilizing video encoding"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "pointed to qimage data and utilizing video encoding"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "X11FilterContext_9905 destroyX11Resources.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "force the stride to ensure we can safely set ximage data ptr to qimage data ptr. This is a video-related operation.",
                    "force the stride to ensure we can safely set ximage data ptr to qimage data ptr. This is a video-related operation."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "X11FilterContext_9905 renderTextImageX11.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "initialize something, such as environment check, related to video playback."
        ],
        "FuncName": "Logger_9763 critical.txt"
    },
    {
        "Branch": [
            "If-Condition-Str: Video code for conditional rendering",
            "If-Condition-Str: Conditional rendering is a technique used in video production to control the display of video content based on certain conditions",
            "If-Condition-Str: This can be useful for creating interactive video experiences"
        ],
        "Loop": [
            "Loop-Condition-Str: Video code for looping",
            "Loop-Condition-Str: Looping in video production refers to the repetition of a video or animation sequence",
            "Loop-Condition-Str: This can be used to create seamless transitions or to emphasize certain points in the video"
        ],
        "Normal": [
            "qpainter transform etc: Video code for graphics rendering",
            "qpainter transform etc: QPainter is a graphics rendering engine used in Qt to draw 2D graphics",
            "qpainter transform etc: Transformations such as rotation, scaling, and translation can be applied to graphics elements using QPainter"
        ],
        "FuncName": "X11FilterContext_9905 drawImage.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Initialize QtAV Debug with log level and log tag, print QtAV information.",
            "Print log message with format %s\n",
            "Check environment variables and call other functions on first Qt logging call.",
            "Override log level setting."
        ],
        "FuncName": "Logger_9763 QtAVDebug.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "painter->save() for video rendering",
            "transform at last because clip_path is relative to paint device coordinate system used in video playback"
        ],
        "FuncName": "X11FilterContext_9905 prepare.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "should check every registered video encoder"
        ],
        "FuncName": "VideoEncoder_5361 supportedCodecs.txt"
    },
    {
        "Branch": [
            " video if condition: conditional rendering of video content"
        ],
        "Loop": [
            " video loop condition: looping video playback"
        ],
        "Normal": [
            " video painter transform etc: video rendering and transformation"
        ],
        "FuncName": "X11FilterContext_9905 drawImage.txt"
    },
    {
        "Branch": [
            "factory.h does not check whether an id is registered in video encoder"
        ],
        "Loop": [],
        "Normal": [
            "factory.h does not check whether an id is registered in video encoder"
        ],
        "FuncName": "VideoEncoder_5361 VideoEncoder_RegisterAll.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " replace illegal chars in title with . and select video stream",
            " Video stream is empty",
            " Video stream has only one stream, no selection needed",
            " Video stream has more than one stream, selection is needed"
        ],
        "FuncName": "parserBase_7881 finishParsing.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "painter translate rect topLeft drawContent can not set target rect move here",
            "reset O let painter draw from 0",
            "painter start from mapped top left relative to mapped rect top left",
            "video debugging output r",
            "TODO use boundingRect for video rendering"
        ],
        "FuncName": "X11FilterContext_9905 drawRichText.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "how to compute mSecsTotal only once, typically done by parsing video metadata",
            "why video.total_time may be wrong due to mkv container issues"
        ],
        "FuncName": "OSD_3693 text.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "Calculating plane sizes and total bitrate for video encoding."
                ]
            }
        ],
        "Normal": [
            "TODO: call later when bpp need",
            "libavutil55: depth, step, offset for video processing."
        ],
        "FuncName": "VideoFormat_5259 initBpp.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Now do extended addition and prepare for multiplication",
                    "Add ls DWORDs and propagate carry",
                    "Add 2nd most ls DWORDs and propagate carry",
                    "Add MS DWORDLONGs - no carry expected",
                    "Now see if we got a sign change from the addition and prepare for division",
                    "Prepare to negate the current value if necessary"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Check if -d < 0 and prepare for division"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Negate the current value (ugh!) and prepare for division"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "ASSERT(p[1].HighPart == 0 && p[1].LowPart < dwDivisor);",
                    "Prepare for division and handle exceptions if the result does not fit in a DWORD"
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "Shift 128 bit p left 1 and compare",
                    "Compare and prepare for next iteration"
                ]
            }
        ],
        "Normal": [
            "Compute the absolute values to avoid signed arithmetic problems and prepare for multiplication",
            "Do long multiplication and handle overflow",
            "This next computation cannot overflow into p[1].HighPart because the max number we can compute here is: (2 ** 32 - 1) * (2 ** 32 - 1) + // ua.LowPart * ub.LowPart (2 ** 32) * (2 ** 31) * (2 ** 32 - 1) * 2 // x.LowPart * y.HighPart * 2 == 2 ** 96 - 2 ** 64 + (2 ** 64 - 2 ** 33 + 1) == 2 ** 96 - 2 ** 33 + 1 < 2 ** 96",
            "Now for the division and handle c == 0 and overflow",
            "Do the division and handle dividend and divisor types",
            "If the dividend is a DWORD_LONG use the compiler for division",
            "If the divisor is a DWORD then its simpler for division",
            "OK - do long division and handle exceptions"
        ],
        "FuncName": "arithutil_695 llMulDiv.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Find the default device for video output"
        ],
        "FuncName": "PortAudioCommon_6772 getDeviceIndexForOutput.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Capturing video using m_player."
        ],
        "FuncName": "playerwindow_5392 capture.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Port is dealt with separately since it is available as an integer. The port number is typically used to identify a specific video stream or a group of related video streams."
        ],
        "FuncName": "qhttpconnection_1395 createUrl.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Bind referer and user-agent for video playback",
            "Download video for offline playback",
            "Add video to playlist for later playback"
        ],
        "FuncName": "parserBase_7881 finishStreamSelection.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "* set HTTP method for video streaming *",
            "* set HTTP version for video streaming *",
            "* get parsed URL for video streaming *",
            "Insert last remaining header for video streaming",
            "* set client information for video streaming *",
            "Video streaming is ready to go!"
        ],
        "FuncName": "qhttpconnection_1395 HeadersComplete.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "header names are always lower-cased",
                    "clear header value. this sets up a nice",
                    "feedback loop where the next time",
                    "HeaderValue is called, it can simply append",
                    "video-related: HTTP request headers are used to convey video metadata, such as video title, description, and tags"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "insert the header we parsed previously",
            "into the header map",
            "video-related: this step is crucial for video playback, as it allows the server to send video-specific headers to the client"
        ],
        "FuncName": "qhttpconnection_1395 HeaderField.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "ceilPowerOfTwo_loop function measures the performance of a loop that calculates the ceiling power of two in %d clocks.",
            "glm::ceilPowerOfTwo function measures the performance of a mathematical function that calculates the ceiling power of two in %d clocks."
        ],
        "FuncName": "gtc_round_9220 perf.txt"
    },
    {
        "Branch": [
            "If the condition is true, jump to the specified position."
        ],
        "Loop": [
            "Loop until the condition is met, jump to the specified position."
        ],
        "Normal": [
            "Jump to the specified position."
        ],
        "FuncName": "playerwindow_5392 seek.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "The QHttpRequest should not be parented to this, since it's memory management is the responsibility of the user of the library. This is a video request, which requires specific video-related metadata, such as resolution, frame rate, and video codec."
        ],
        "FuncName": "qhttpconnection_1395 MessageBegin.txt"
    },
    {
        "Branch": [
            "TODO: send HTTP request to server"
        ],
        "Loop": [
            "TODO: send HTTP request to server and wait for completion"
        ],
        "Normal": [
            "TODO: send HTTP request to server and wait for completion; Video request sent successfully"
        ],
        "FuncName": "qhttpconnection_1395 MessageComplete.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "sequential device returns bytesAvailable, device size is calculated based on video frame rate and resolution"
        ],
        "FuncName": "QIODeviceIO_9519 size.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "The window has been activated, but the video is not playing."
        ],
        "FuncName": "winutil_1513 InactivateWindow.txt"
    },
    {
        "Branch": [
            "If the video is playing, then"
        ],
        "Loop": [
            "Loop the video until it is finished"
        ],
        "Normal": [
            "enable alpha setting",
            "This setting is used to adjust the transparency of the video"
        ],
        "FuncName": "AmlWindow_732 AmlWindow.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Audio fading effect applied with a gentle decrease in volume over time."
        ],
        "FuncName": "Common_2407 doFadeOut.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " \u4e0d\u8981\u5982\u679c\u6211\u4eec\u88ab\u62e5\u6709\uff0c\u4f18\u5316\u7a97\u53e3\u6027\u80fd",
            " \u5de6\u8fb9\u548c\u9876\u90e8\u8fb9\u7f18\u5bf9\u9f50DWORD\u754c\u9650\uff0c\u9002\u5408\u89c6\u9891\u64ad\u653e",
            " \u4e0d\u8981\u663e\u793a\u7a97\u53e3\uff0c\u63d0\u9ad8\u89c6\u89c9\u4f53\u9a8c"
        ],
        "FuncName": "winutil_1513 PerformanceAlignWindow.txt"
    },
    {
        "Branch": [
            "We must own the window lock during the change, otherwise the window color palette will not be set correctly."
        ],
        "Loop": [],
        "Normal": [
            "We must own the window lock during the change, and then we can set the window color palette."
        ],
        "FuncName": "winutil_1513 SetPalette.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Change Z-order only, activate window"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Has the window been sized and positioned already, related to video playback",
            "Calculate the desired client rectangle for video display",
            "Align left and top edges on DWORD boundaries for video alignment",
            "Don't show window, video is not playing"
        ],
        "FuncName": "winutil_1513 ActivateWindow.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "IMPORTANT: this causes video to be drained instead of flushed.",
            "This issue needs to be investigated.",
            "int video_fd = OpenDevice();",
            "int params[4]{ x, y, x + width, y + height };",
            "Set video axis position and size.",
            "int ret = ioctl(video_fd, AMSTREAM_IOC_SET_VIDEO_AXIS, &params);",
            "",
            "CloseDevice(video_fd);",
            "if (ret < 0)",
            "{",
            "\tthrow Exception(ioctl AMSTREAM_IOC_SET_VIDEO_AXIS failed.);",
            "}"
        ],
        "FuncName": "AmlWindow_732 SetVideoAxis.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Restore default VGA color palette for video playback"
        ],
        "FuncName": "winutil_1513 UnsetPalette.txt"
    },
    {
        "Branch": [
            "The video requires a specific window color palette"
        ],
        "Loop": [
            "The video loop will be affected by the color palette change"
        ],
        "Normal": [
            "We must own the window lock during the change to apply the color palette"
        ],
        "FuncName": "winutil_1513 SetPalette.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Have we already cleaned up video-related objects?",
            "Release the video window resources to free up memory",
            "Reset video window variables to their default state"
        ],
        "FuncName": "winutil_1513 UninitialiseWindow.txt"
    },
    {
        "Branch": [
            "Check if the video is playing and the window is not minimized"
        ],
        "Loop": [
            "Loop through each frame of the video"
        ],
        "Normal": [
            "Initialise the window variables",
            "Set the video playback position to 0",
            "Start playing the video"
        ],
        "FuncName": "winutil_1513 InitialiseWindow.txt"
    },
    {
        "Branch": [
            "ASSERT(m_hdc); Window size: {{width}}, {{height}}"
        ],
        "Loop": [
            "ASSERT(m_hdc); Video loop: {{loopCount}} times, Window size: {{width}}, {{height}}"
        ],
        "Normal": [
            "ASSERT(m_hdc); Video playback: Window size: {{width}}, {{height}}"
        ],
        "FuncName": "winutil_1513 GetDefaultRect.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Register the renderer window class",
                    "Create a window to render video"
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            "Render video in a loop"
        ],
        "Normal": [
            "Used to register classes for video rendering",
            "Check if video rendering class is registered",
            "Get a handle to the video rendering window",
            "Get video rendering info structure",
            "If the video window is to be used for drawing purposes and we are getting a DC",
            "Change the class style to enable video rendering for the entire lifetime of the window",
            "Ensure the DC is not cached for video rendering",
            "Create a frame window for video rendering. Pass the pBaseWindow information in the CreateStruct",
            "Set the owner window object for video rendering",
            "Pass creation data for video rendering",
            "If video rendering fails, signal an error to the object constructor and exit",
            "Check the window LONG is the object who created the video window",
            "Initialise the video window and signal the constructor to continue",
            "Unlock the object's critical section and allow the operating system to free the class resources"
        ],
        "FuncName": "winutil_1513 DoCreateWindow.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Register the renderer window class for video rendering",
                    "Prepare the window for video playback"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Used to register classes for video playback",
            "Is this class registered for video rendering",
            "Handle to our video window",
            "Info structure for video playback",
            "if the window is to be used for video purposes and we are getting a DC",
            "for the entire lifetime of the window then changes the class style to do",
            "say so. If we don't set this flag then the DC comes from the cache and is",
            "really bad.",
            "Create the frame window for video playback.  Pass the pBaseWindow information in the",
            "CreateStruct which allows our message handling loop to get hold of",
            "the pBaseWindow pointer for video rendering.",
            "The owner window object for video playback",
            "Creation data for video window",
            "If we failed signal an error to the object constructor (based on the",
            "last Win32 error on this thread) then signal the constructor thread",
            "to continue, release the mutex to let others have a go and exit",
            "Check the window LONG is the object who created us for video rendering",
            "Initialise the window and then signal the constructor so that it can",
            "continue and then finally unlock the object's critical section. The",
            "window class is left registered even after we terminate the thread",
            "as we don't know when the last window has been closed. So we allow",
            "the operating system to free the class resources as appropriate"
        ],
        "FuncName": "winutil_1513 OnReceiveMessage.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "To avoid deadlock, we should not grab the critical section while realizing the palette on the window thread.",
            "Instead, we should let the window thread handle the palette realization, which may send a WM_PALETTECHANGED message to other windows.",
            "In our WM_PALETTECHANGED handler, we should not grab the critical section either, as it may cause a deadlock with the renderer's DoRealisePalette() call.",
            "The correct approach is to let USER manage palette handling, and avoid serializing everything unnecessarily.",
            "Realizing the palette on the memory DC is a better approach, as it avoids the potential deadlock and allows for more efficient handling of palette changes.",
            "By doing so, we can ensure that the palette is realized correctly and efficiently, without introducing any deadlocks or performance issues.",
            "In summary, we should not hold the critical section while realizing the palette, and instead let the window thread handle it, while the renderer focuses on realizing the palette on the memory DC."
        ],
        "FuncName": "winutil_1513 DoRealisePalette.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "If we grab a critical section here we can deadlock with the window thread because one of the side effects of RealizePalette is to send a WM_PALETTECHANGED message to every window in the system. In our handling of WM_PALETTECHANGED we used to grab this CS too. The really bad case is when our renderer calls DoRealisePalette() while we're in the middle of processing a palette change for another window. So don't hold the critical section while actually realising the palette. In any case USER is meant to manage palette handling - we shouldn't have to serialize everything as well. This is a common issue in video processing where multiple threads are accessing the same resource, resulting in a deadlock. To avoid this, we need to synchronize access to the resource using a critical section.",
            "with the window thread because one of the side effects of RealizePalette is to send a WM_PALETTECHANGED message to every window in the system.  In our handling of WM_PALETTECHANGED we used to grab this CS too.  The really bad case is when our renderer calls DoRealisePalette() while we're in the middle of processing a palette change for another window.",
            "So don't hold the critical section while actually realising the palette.  In any case USER is meant to manage palette handling - we shouldn't have to serialize everything as well.  This is a common issue in video processing where multiple threads are accessing the same resource, resulting in a deadlock.  To avoid this, we need to synchronize access to the resource using a critical section.",
            "In our handling of WM_PALETTECHANGED we used to grab this CS too.  The really bad case is when our renderer calls DoRealisePalette() while we're in the middle of processing a palette change for another window.",
            "So don't hold the critical section while actually realising the palette.  In any case USER is meant to manage palette handling - we shouldn't have to serialize everything as well.  This is a common issue in video processing where multiple threads are accessing the same resource, resulting in a deadlock.  To avoid this, we need to synchronize access to the resource using a critical section.",
            "The really bad case is when our renderer calls DoRealisePalette() while we're in the middle of processing a palette change for another window.",
            "So don't hold the critical section while actually realising the palette.  In any case USER is meant to manage palette handling - we shouldn't have to serialize everything as well.  This is a common issue in video processing where multiple threads are accessing the same resource, resulting in a deadlock.  To avoid this, we need to synchronize access to the resource using a critical section.",
            "In any case USER is meant to manage palette handling - we shouldn't have to serialize everything as well.  This is a common issue in video processing where multiple threads are accessing the same resource, resulting in a deadlock.  To avoid this, we need to synchronize access to the resource using a critical section.",
            "This is a common issue in video processing where multiple threads are accessing the same resource, resulting in a deadlock.  To avoid this, we need to synchronize access to the resource using a critical section."
        ],
        "FuncName": "winutil_1513 DirectShowWndProc.txt"
    },
    {
        "Branch": [
            "GetWindowWidth() is used to retrieve the width of the current window."
        ],
        "Loop": [],
        "Normal": [
            "ASSERT(m_hdc); // The device context is valid for drawing the video content."
        ],
        "FuncName": "winutil_1513 GetWindowWidth.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Draws a video image from a media sample, utilizing fast rendering via image allocator for efficient processing and optional DirectDraw surface pointer for accelerated drawing.",
            "If the output pin utilizes our allocator, the samples passed are in fact CVideoSample objects containing CreateDIBSection data for faster image rendering.",
            "In this case, the samples may also include a DirectDraw surface pointer, preventing the need for additional drawing operations.",
            "This is a DIBSECTION buffer optimized for video image rendering."
        ],
        "FuncName": "winutil_1513 DrawImage.txt"
    },
    {
        "Branch": [
            "ASSERT(m_hdc); If the window is not active, return the height of the inactive window."
        ],
        "Loop": [
            "ASSERT(m_hdc); Loop through each frame of the video and calculate the height of each frame."
        ],
        "Normal": [
            "ASSERT(m_hdc); The window height is returned as the maximum height of all frames."
        ],
        "FuncName": "winutil_1513 GetWindowHeight.txt"
    },
    {
        "Branch": [
            "ASSERT(m_hdc && \"Window handle is valid for if condition\")"
        ],
        "Loop": [
            "ASSERT(m_hdc && \"Window handle is valid for loop condition\")"
        ],
        "Normal": [
            "ASSERT(m_hdc && \"Window handle is valid\")"
        ],
        "FuncName": "winutil_1513 GetWindowHWND.txt"
    },
    {
        "Branch": [
            "If the video is paused, display a pause icon.",
            "If the video is playing, display a play icon."
        ],
        "Loop": [
            {
                "loopstr": [
                    "For each frame in the video, create a new image sample.",
                    "Pass the frame data to the sample object.",
                    "Add the completed sample to the available list."
                ]
            }
        ],
        "Normal": [
            "Check if the video is still playing.",
            "Create a new memory mapped object for each frame.",
            "Map the frame data into the address space.",
            "Display the frame on the screen.",
            "If the video is finished, display a finish icon."
        ],
        "FuncName": "winutil_1513 Alloc.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Format information for pin video data",
            "Pointer to the actual video image frame buffer",
            "Handle to mapped video object",
            "DIB section bitmap handle for video display",
            "Create a file mapping object and map video data into our address space",
            "No name to section for video data",
            "NOTE We always create a DIB section with the source video format type which",
            "may contain a source video palette. When we do the video BitBlt drawing operation",
            "the target display device may contain a different palette (we may not",
            "have the focus) in which case GDI will do after the palette mapping",
            "Offset into memory for video data",
            "Initialise the DIB information structure for video display"
        ],
        "FuncName": "winutil_1513 CreateDIB.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Render the video sample to the window",
                    "Video type: palette"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Get the BITMAPINFOHEADER for the video connection",
            "Get the video image data buffer",
            "This allows derived classes to change the source rectangle for video rendering",
            "For example, a renderer may ask a codec to stretch the video from 320x240 to 640x480",
            "In this case, the source we see in the code will still be 320x240, although the source we want to draw with",
            "should be scaled up to 640x480. The base class implementation of this method does nothing but return the same rectangle as we are passed in",
            "if the origin of the video bitmap is bottom-left, adjust the source rectangle top",
            "to be the bottom-left corner instead of the top-left.",
            "Is the window the same size as the video",
            "This shows the sample reference times over the top of the video image which",
            "looks a little flickery. I tried using GdiSetBatchLimit and GdiFlush to control the screen updates but it doesn't quite work as expected and",
            "only partially reduces the flicker. I also tried using a memory context and combining the two in that before doing a final BitBlt operation to",
            "the screen, unfortunately this has considerable performance penalties and also means that this code is not executed when compiled retail"
        ],
        "FuncName": "winutil_1513 SlowRender.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Draw the image directly onto the window",
                    "Perform a simple copy operation"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Media sample image format data",
            "Stores DIB information for the image",
            "Pointer to the image data in the media sample",
            "Store the old bitmap to prevent memory leaks",
            "Pointer to a C++ object representing the image",
            "Retrieve the VIDEOINFO and BITMAPINFOHEADER structures from the untyped source format block",
            "Cast the IMediaSample interface to a CImageSample object to access its DIBSECTION details",
            "Obtain a pointer to the actual image data",
            "Check if the color table needs to be updated, incrementing the palette cookie for dynamic format changes",
            "Synchronize the DIBDATA structure with the sample palette cookie",
            "Wait for the format change to complete, then retrieve the renderer's palette version",
            "Allow derived classes to modify the source rectangle for drawing, potentially scaling the video",
            "Return the same rectangle as passed in, performing no scaling or modifications",
            "Verify that the window size matches the video size",
            "Display sample times over the image, avoiding writing to the image data buffer",
            "Restore the old bitmap to the device context, preventing memory leaks"
        ],
        "FuncName": "winutil_1513 FastRender.txt"
    },
    {
        "Branch": [
            "Check if the target area and source area have different dimensions"
        ],
        "Loop": [],
        "Normal": [
            "Calculate the overall rectangle dimensions and determine if stretching is required"
        ],
        "FuncName": "winutil_1513 SetStretchMode.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "We may not have a current video format yet",
            "Both video formats may require a color palette update",
            "Compare the video colors to see if they match the updated palette"
        ],
        "FuncName": "winutil_1513 ShouldUpdate.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "Turn off the bottommost bit",
                    "Perform bit counting for video encoding"
                ]
            }
        ],
        "Normal": [
            "This is a relatively well known bit counting algorithm for video compression",
            "Until the input is exhausted, count the number of bits for video data"
        ],
        "FuncName": "winutil_1513 CountSetBits.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Verify video image width and height are non-negative.",
            "Confirm compression type is either BI_RGB or BI_BITFIELDS.",
            "For BI_BITFIELDS compression, validate colour depth.",
            "Inspect layout assumptions about the bit fields.",
            "Ensure the number of planes equals one.",
            "Validate the image size consistency (it can be zero).",
            "Verify the structure size."
        ],
        "FuncName": "winutil_1513 CheckHeaderValidity.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "First of all work out how many bits are set",
                    "Next work out the number of zero bits prefix",
                    "This is going to see if all the bits set are contiguous (as they",
                    "should be). We know how much to shift them right by from the",
                    "count of prefix bits. The number of bits set defines a mask, we",
                    "invert this (ones complement) and AND it with the shifted bit",
                    "fields. If the result is NON zero then there are bit(s) sticking",
                    "out the left hand end which means they are not contiguous. This",
                    "is a common issue in video encoding, where bits are not",
                    "contiguous due to padding or other factors."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "winutil_1513 CheckBitFields.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "f32: "
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "f32: "
                ]
            }
        ],
        "Normal": [
            "f32: "
        ],
        "FuncName": "gtc_packing_3369 print_bits.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Print 10 binary digits: "
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "Iteration: %d"
                ]
            }
        ],
        "Normal": [
            "Binary representation of 10: "
        ],
        "FuncName": "gtc_packing_3369 print_10bits.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "The checks here are for palettised videos only; this involves video type and color palette.",
            "Compression type of BI_BITFIELDS is meaningless for palette video; BI_BITFIELDS is a type of video compression.",
            "Check the number of palette colours is correct; video color palette must be accurate.",
            "The number of important colours shouldn't exceed the number used; video color usage should be efficient."
        ],
        "FuncName": "winutil_1513 CheckPaletteHeader.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Make sure that the window's palette handle matches our palette handle.",
                    "our palette handle.",
                    "Remove the video palette to ensure a seamless video playback experience."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Do we have a video palette to remove for optimal video playback?"
        ],
        "FuncName": "winutil_1513 RemovePalette.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "interop operations end, video rendering complete"
        ],
        "FuncName": "SurfaceInteropD3D11GL_4862 unmap.txt"
    },
    {
        "Branch": [
            "Check if the video codec is supported."
        ],
        "Loop": [],
        "Normal": [
            "Verify if the video codec is supported."
        ],
        "FuncName": "AudioPlayerWasapi_5654 CreateDeviceEnumerator.txt"
    },
    {
        "Branch": [
            "Ensure DX11 texture resources are created and updated for conditional statements in video code."
        ],
        "Loop": [
            "Ensure DX11 texture resources are created and updated for loop conditions in video code."
        ],
        "Normal": [
            "required by d3d9 not d3d10&11: https://www.opengl.org/registry/specs/NV/DX_interop2.txt"
        ],
        "FuncName": "SurfaceInteropD3D11GL_4862 ensureResource.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Set as not synchronized, with AV video frames inserted"
        ],
        "FuncName": "VkVideoVulkan_7032 insertAvailableAvVkFrames.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Floating-point number: %2.5f, Binary representation: ",
            ", Binary representation: ",
            "\tprint_11bits(detail::floatTo11bit(s)):\t%s\t\t// 11-bit binary representation",
            "\tprintf(,, %f):\t%s\t\t// Floating-point number and binary representation",
            "\tprint_10bits(detail::floatTo10bit(s)):\t%s\t\t// 10-bit binary representation",
            "\n"
        ],
        "FuncName": "gtc_packing_3369 print_value.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "open/close and register/unregister in every map/unmap to ensure called in current context and avoid crash (tested on intel driver), D3D11 texture mapped to OpenGL",
            "interop operations begin, D3D11-OpenGL interoperability",
            "call in ensureResource or in map, D3D11 resource preparation for OpenGL",
            "prepare dx resources for gl, D3D11-OpenGL resource mapping",
            "lock dx resources, D3D11 texture locking for OpenGL access"
        ],
        "FuncName": "SurfaceInteropD3D11GL_4862 map.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    " Flush the draw command now. Ideally, this should be done immediately before the draw call that uses the texture. Flush it once here though.",
                    "StretchRect does not supports odd values",
                    " ensure data is copied to egl surface. Solution and comment is from chromium.",
                    " DXVA decoder output is mapped to EGL surface using DirectX surface mapping.",
                    " The DXVA decoder has its own device which it uses for decoding. ANGLE has its own device which we don't have access to.",
                    " The above code attempts to copy the decoded picture into a surface which is owned by ANGLE, utilizing video decoding and EGL surface mapping.",
                    " As there are multiple devices involved in this, the StretchRect call above is not synchronous, requiring video decoding synchronization.",
                    " We attempt to flush the batched operations to ensure that the picture is copied to the surface owned by ANGLE, ensuring video decoding completion.",
                    " We need to do this in a loop and call flush multiple times, due to asynchronous video decoding.",
                    " We have seen the GetData call for flushing the command buffer fail to return success occassionally on multi core machines, leading to an infinite loop, indicating video decoding synchronization issues.",
                    " Workaround is to have an upper limit of 10 on the number of iterations to wait for the Flush to finish, ensuring video decoding completion within a reasonable time."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "SurfaceInteropD3D9EGL_9917 map.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Printing 11 binary digits: 00000000011"
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "Printing 11 binary digits: 00000000011"
                ]
            }
        ],
        "Normal": [
            "Printing 11 binary digits: 00000000011"
        ],
        "FuncName": "gtc_packing_3369 print_11bits.txt"
    },
    {
        "Branch": [
            "If the video is playing, then the player is active."
        ],
        "Loop": [
            "While the video is playing, the player is active."
        ],
        "Normal": [
            "ASSERT(IsVideoSupported());"
        ],
        "FuncName": "AudioPlayerWasapi_5654 GetSharedModeMixFormat.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "ASSERT(IsSupported());",
            "Create the IMMDeviceEnumerator interface.",
            "Retrieve an audio device specified by an endpoint device-identification string.",
            "Configure the audio device for video playback.",
            "Set the audio device as the default device for video playback."
        ],
        "FuncName": "AudioPlayerWasapi_5654 CreateDevice.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "ASSERT(IsSupported()); generates audio for video playback."
        ],
        "FuncName": "AudioPlayerWasapi_5654 CreateDefaultClient.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "ASSERT(IsSupported()); Creates and activates an IAudioClient COM object given the selected endpoint device.",
            "Creates and activates an IAudioClient COM object given the selected endpoint device."
        ],
        "FuncName": "AudioPlayerWasapi_5654 CreateClient.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Audio playback initiated: opening audio player and initializing audio stream.",
            "Initializing audio client and setting audio format for default rendering device.",
            "Creating audio client interface for default rendering IMMDevice.",
            "Configuring WAVEFORMATEX structure for basic audio format.",
            "Adding extended format components to WAVE_FORMAT_EXTENSIBLE.",
            "Setting audio channel mask to render using CoreAudioUtil.GetChannelConfig.",
            "Initializing shared audio stream between client and device using event-driven buffer handling.",
            "Creating IAudioRenderClient client for initialized IAudioClient.",
            "Enabling output data writing to rendering endpoint buffer using IAudioRenderClient.",
            "Storing valid COM interfaces for audio rendering."
        ],
        "FuncName": "AudioPlayerWasapi_5654 Open.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "ASSERT(IsSupported());",
            "Get access to the IAudioRenderClient interface. This interface enables us to write output data to a rendering endpoint buffer."
        ],
        "FuncName": "AudioPlayerWasapi_5654 CreateRenderClient.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " Iterate packets starting when found keyframe, parsing video frames and extracting relevant metadata for analysis"
        ],
        "FuncName": "PacketBuffer_3026 iterate.txt"
    },
    {
        "Branch": [
            "OpenGL indirect resource unlock and release"
        ],
        "Loop": [],
        "Normal": [
            "OpenGL indirect resource unlock and release: interop operations end"
        ],
        "FuncName": "SurfaceInteropD3D9GL_2784 unmap.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "In video processing, a new time segment is created and sent to the queue to maintain order.",
                    " we need to queue the new segment to appear in order in the",
                    " data, but we need to pass parameters to it. Rather than",
                    " take the hit of wrapping every single sample so we can tell",
                    " special ones apart, we queue special pointers to indicate",
                    " special packets, and we guarantee (by holding the",
                    " critical section) that the packet immediately following a",
                    " NEW_SEGMENT value is a NewSegmentPacket containing the",
                    " parameters.",
                    "This is specific to video processing, where segments are a crucial aspect."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "outputq_6528 NewSegment.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "pass this downstream, buffer video stream"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "outputq_6528 BeginFlush.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "m_bSendAnyway is a private parameter checked in ReceiveMultiple. This is a video related description."
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "thenstr": [
                    "Loop through video frames to check video quality."
                ],
                "elsestr": []
            }
        ],
        "Normal": [
            {
                "thenstr": [
                    "Video playback is normal. No errors occurred."
                ],
                "elsestr": []
            }
        ],
        "FuncName": "outputq_6528 SendAnyway.txt"
    },
    {
        "Branch": [
            "Ensure the creation and deletion of resources for if conditions.",
            "Required for video processing."
        ],
        "Loop": [
            "Ensure the creation and deletion of resources for loop conditions.",
            "Required for video processing."
        ],
        "Normal": [
            "A8 for a yuv plane: Ensure the creation and deletion of resources for A8 planes in yuv video processing.",
            "Required by d3d9 not d3d10&11: Ensure the creation and deletion of resources for compatibility with d3d9 in video processing, as specified in https://www.opengl.org/registry/specs/NV/DX_interop2.txt."
        ],
        "FuncName": "SurfaceInteropD3D9GL_2784 ensureResource.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "DbgLog((LOG_TRACE,3,TEXT(Queue: Delivered  SET EVENT))); Video processing started."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "If its just a regular sample just add it to the batch. Video sample added to batch.",
                    "and exit the loop if the batch is full"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Tell other thread to set the event when there's something to do. Video thread notified."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "now we need the parameters - we are guaranteed that the next packet contains them. Video parameters received.",
                    "we took something off the queue"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "DbgLog((LOG_TRACE,3,TEXT(Queue: Delivered  SET EVENT))); Video processing completed."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "We look at m_nBatched from the client side so keep it up to date inside the critical section. Video batch count updated.",
                    "Local copy"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Don't overwrite a flushing state HRESULT Video flushing state maintained."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "In any case wait for more data - S_OK just means there wasn't an error. Video waiting for more data."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "We don't send even end of stream on if we've previously returned something other than S_OK. Video end of stream not sent.",
                    "This is because in that case the pin which returned something other than S_OK should have either sent EndOfStream() or notified the filter graph"
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "Local copy",
                    "",
                    "Get a batch of samples and send it if possible. Video batch sent.",
                    "In any case exit the loop if there is a control action requested.",
                    "",
                    "Wait for some more data. Video waiting for more data.",
                    "OK - send it if there's anything to send. Video data sent.",
                    "We DON'T check m_bBatchExact here because either we've got a full batch or we dropped through because we got SEND_PACKET or EOS_PACKET - both of which imply we should flush our batch.",
                    "Check for end of stream. Video end of stream checked.",
                    "Data from a new source. Video new source detected."
                ]
            },
            {
                "loopstr": [
                    "Get a sample off the list. Video sample retrieved.",
                    "inform derived class we took something off the queue"
                ]
            }
        ],
        "Normal": [],
        "FuncName": "outputq_6528 ThreadProc.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "hwa extra finalize can be here. This is a video stream."
        ],
        "FuncName": "AVEncoder_5291 close.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "if dict is empty, can not return here, default options will be set for video encoding",
            "apply to video encoding settings",
            "set video encoder options. * we do not check whether the property exists thus we can set dynamic properties for video encoding."
        ],
        "FuncName": "AVEncoder_5291 setOptions.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Optimize - no need to signal if it's not waiting. Release the semaphore when waiting is finished in video processing."
        ],
        "FuncName": "outputq_6528 NotifyThread.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "dest should be avcodec_alloc_context3(NULL)",
                    "AVcodec context allocation"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "AVEncoder_5291 copyAVCodecContext.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "already 0 in av_free. Video decoding is a complex process that involves converting compressed video data into a format that can be displayed on a screen. The 'av_free' function is likely used to free up memory allocated for video decoding, ensuring efficient use of system resources."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            " TODO: use QVariantMap only. In video processing, QVariantMap can be used to efficiently store and manage video metadata, such as resolution, frame rate, and codec information.",
            "workaround for VideoDecoderFFmpeg. now it does not call av_opt_set_xxx, so set here in dict. The VideoDecoderFFmpeg is a workaround for a specific issue where the 'av_opt_set_xxx' function is not being called, requiring a manual set in the dictionary to ensure proper video decoding.",
            " TODO: wrong if opt is empty. In video processing, if an option is empty, it can lead to incorrect video decoding or playback. This TODO comment highlights the need to handle empty options correctly to ensure smooth video playback."
        ],
        "FuncName": "AVEncoder_5291 applyOptionsForDict.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "handle unknown option",
                    "This is a conditional statement in a video script."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "qDebug(%d %s, __LINE__, qPrintable(it_list->value().toString()));",
                    "This code is used to debug the video script."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "",
                    "qDebug(%d %s, __LINE__, qPrintable(it_list->value().toString()));",
                    "This is a blank line in the video script."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "handle unknown option",
                    "This is another conditional statement in a video script."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "-o abco",
                    "qDebug(%d %s, __LINE__, qPrintable(it_list->value().toString()));",
                    "This option is used to output the video script."
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "loopstr": [
                    "usally is 1",
                    "This is a loop condition in a video script.",
                    "TODO: startsWith(-height,-h) Not endsWith, -oabco"
                ]
            }
        ],
        "Normal": [],
        "FuncName": "qoptions_4211 parse.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "We're idle if there is no thread (!IsQueued()) or the thread is waiting for more work (m_lWaiting != 0) and there's nothing in the current batch (m_nBatched == 0)"
        ],
        "FuncName": "outputq_6528 IsIdle.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "collect and deliver media samples within the specified time range",
            "ensure pSample is set for optimal video playback"
        ],
        "FuncName": "pullpin_3359 CollectAndDeliver.txt"
    },
    {
        "Branch": [
            "If the video is not ready, connect an asynchronous reader to wait for the video to be ready."
        ],
        "Loop": [
            "Loop through the video frames until the end of the video."
        ],
        "Normal": [
            "convert from file position to reference time"
        ],
        "FuncName": "pullpin_3359 Connect.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Execute deleteLater() in main thread, because in this thread processEvents() might not be called. This is a common pattern in video processing to ensure thread safety."
        ],
        "FuncName": "OpenThr_8008 drop.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "commit allocator",
                    "start thread",
                    "video playback initiated",
                    "video decoding started"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "pullpin_3359 StartThread.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Probably it doesn't work. Vertical sync is enabled to improve video playback quality."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "OpenGLWindow_9256 setVSync.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "adjust times to be relative to (aligned) start time",
                    "repair timestamp of video sample"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "fix up sample if past actual stop (for sector alignment) to ensure video playback continuity"
        ],
        "FuncName": "pullpin_3359 DeliverSample.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "At this point, there should be no outstanding requests on the upstream filter.",
                    "We should force begin/endflush to ensure that this is true.",
                    "Note that we may currently be inside a BeginFlush/EndFlush pair on another thread, but the premature EndFlush will do no harm now that we are idle."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "pullpin_3359 ThreadProc.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "need to flush to ensure the thread is not blocked during video playback",
            "in WaitForNext video frame"
        ],
        "FuncName": "pullpin_3359 PauseThread.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Initialize the video control component and set up UI and event filters.",
            "Connect signals and slots, set volume and background image, and link it with VideoPlayerWidget.",
            "Default value from the decoder enhanced with video-related descriptions."
        ],
        "FuncName": "videocontrol_8812 VideoControl.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Video decoding: reading data from MPDemux class",
            "Konwersja 32bit-int na 32bit-float: video frame conversion",
            "Video frame rate: CHN BITS/8"
        ],
        "FuncName": "MPDemux_7688 read.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "why d->initialized (ref==1) result in detach? These lines of code are related to video processing, specifically dealing with AVPacket objects and their references."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "d.data() was 0 if d has not been accessed. now only contains avpkt, check d.constData() is enough. This is an optimization for video playback, ensuring efficient memory usage."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "Packet_9058 asAVPacket.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "OK? The video module is set."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "MPDemux_7688 open.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Use OpenGL if Vulkan is not available. This is a common approach in graphics programming when Vulkan is not supported by the system."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "GPUInstance_5248 create.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Copy ID3v2 to InfoTag",
                    "Covers",
                    "Video metadata"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "TagLib can't load Ogg Opus video file if file extension is .ogg"
        ],
        "FuncName": "TagEditor_2979 open.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Adjusting control size and position for video playback.",
            "Setting margins between X for video layout.",
            "Setting Y position for button placement in video.",
            "Adding +1 for a more visually appealing video."
        ],
        "FuncName": "videocontrol_8812 resizeEvent.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "TestInputs[i] = glm::translate(MAT4(1), Axis * f); This is a translation operation in a video context."
                ]
            }
        ],
        "Normal": [
            "glm::uint Ulp = 0;",
            "Ulp = glm::max(glm::float_distance(*Dst, *Src), Ulp); This is a distance calculation between two 3D models in a video context.",
            "inverse(%s): %lu\\n This is an inverse matrix operation, a common technique used in video processing and computer graphics."
        ],
        "FuncName": "core_func_matrix_473 test_inverse_perf.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Remove ID3 tags from FLAC File",
                    "No ID3v2 in WAV, only InfoTag"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Save current tag information, including song title, artist, album, comments, type, year, and track.",
            "These strings are for video code."
        ],
        "FuncName": "TagEditor_2979 save.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "E.g. for chiptunes without group, video content is available for viewing."
        ],
        "FuncName": "PlaylistDock_955 urlMatchesWithItem.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Display a message box with the video information, including frame rate and resolution"
        ],
        "FuncName": "playuvFrame_6582 pyuvDraw.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "not constructed from AVPacket",
                    "Skipping specific bytes in data packet."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            " TODO: if duration is valid, compute pts/dts and no manually update outside",
            "Related to video type: Skipping specific bytes in data packet for video data."
        ],
        "FuncName": "Packet_9058 skip.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Display a message box with the info about PYUV video codec"
        ],
        "FuncName": "playuvFrame_6582 OnAbout.txt"
    },
    {
        "Branch": [
            "Check if the video is playing and the animation is active"
        ],
        "Loop": [
            "Loop through the video playback and update the animation"
        ],
        "Normal": [
            "Display a message box with the info",
            "Play the video and animate the UI accordingly"
        ],
        "FuncName": "playuvFrame_6582 OnAnimate.txt"
    },
    {
        "Branch": [
            "Check if a condition is met in the video script"
        ],
        "Loop": [
            "Specify the loop condition for the video playback"
        ],
        "Normal": [
            "Display a message box with the info and play the video"
        ],
        "FuncName": "playuvFrame_6582 readfile.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Display a message box with the info about video file parameters"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Increment hints counter"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Load the first chunk of the video file",
                    "Read the file in binary mode",
                    "Seek to the beginning of the file",
                    "Scan the file for parameters such as width, height, frame rate, etc."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Not enough info collected, look for header file in the same directory",
                    "Components and subsampling information",
                    "There are too few matches, ask the user for input",
                    "Display the results of the match",
                    "File and frame size information"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Load the header file from the same directory"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Open the video file",
                    "Traverse all lines in the file"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Increment hints counter"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Set the color space number based on the format",
                    "Increment hints counter by 3"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Check if frame dimensions fit inside the display dimensions",
                    "Fix the check menu item",
                    "Update scaled dimensions",
                    "Set up video playback",
                    "Do a one-shot timer tick",
                    "Associate the drawing image with the video",
                    "Store the file in history"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "For automatic parameter setup, the following actions are performed",
            "",
            "1: if the extension is .vix, then the header is parsed to setup the parameters",
            "",
            "2: the filename can contain the following tokens, in any order",
            "",
            "whatever_{width}x{height}_{rate}Hz_{format}_{depth}b_g{gamma}.{ext}",
            "",
            "{width}  = integer number, the frame width in pixel",
            "{height} = integer number, the frame height in pixel",
            "{rate}   = real number, the frames per second to be rendered",
            "{format} = sampling format. See help for valid choices",
            "{depth}  = integer number between -15 and 15, the component depth in bits",
            "            (negative values denote a signed format for that depth)",
            "{ext}    = 3-letter abbreviation of the colorspace (can be anywhere in the filename, also)",
            "{gamma}  = gamma correction value multiplied by 10, without commas or points",
            "",
            "3: a filename with the same base name followed by _ and the extension, ending in .hdr,",
            "is searched in the same directory. It can contain the following lines",
            "",
            "width = XXXX",
            "height = XXXX",
            "rate = XXXX",
            "format = XXXX",
            "depth = XXXX",
            "space = XXXX",
            "gamma = XXXX",
            "",
            "4: a filename pyuvdefault.hdr is searched",
            "",
            "Parse the collected file name",
            "Load the full file name, with the path",
            "First, try to open the file in binary mode",
            "Declare the file",
            "Look for the anamorphic string",
            "Look for the format string",
            "Look for the colorspace string",
            "Find interlacing",
            "Find a frame size",
            "Find a frame rate",
            "Find a gamma value",
            "Find a bit depth",
            "It's a VIX file",
            "Not enough info collected: look for header file"
        ],
        "FuncName": "playuvFrame_6582 openfile.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "If in queue remove from queue and play the video"
        ],
        "FuncName": "PlaylistDock_955 itemDoubleClicked.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "Toggle Locked flag",
                    "This is related to video playback, where the locked flag is toggled."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "PlaylistDock_955 toggleLock.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Don't play skipped item. This action is related to video playback settings."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Break and stop playback if played everything ignoring skipped entries. This behavior is common in video players."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Video playback will stop due to missing information. This is a common issue in video playback."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "PlaylistDock_955 next.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Initializing DXVA2 OpenGL functionality is crucial for Intel drivers, as it prevents rendering target release issues due to potential failures in wglDXSetResourceShareHandleNV().",
                    "For Radeon drivers, re-creating the rendering target is necessary to avoid failures in wglDXRegisterObjectNV()."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "DXVA2OpenGL_8581 init.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Toggle video playback flag"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "PlaylistDock_955 toggleEntryFlag.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Must be queued to not crash at startup in some cases. Video playback requires a stable playlist to ensure smooth playback."
        ],
        "FuncName": "PlaylistDock_955 PlaylistDock.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "Additional flags",
                    "Save playlist items to a specific URL related to video playback"
                ]
            }
        ],
        "Normal": [],
        "FuncName": "PlaylistDock_955 save.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "printf(diffuseMapParameter=%d\n, diffuseMapParameter);",
                    "QuadBatchProgram vertex attributes activation"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "WorldViewProjection",
            "Diffuse Map",
            "Vertex Attributes",
            "QuadBatchProgram video type description"
        ],
        "FuncName": "QuadBatchProgram_1709 Apply.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Initialize QuadBatchProgram class constructor, setting world view projection matrix and texture coordinates.",
            "glBindAttribLocation(Id(), 0, Attr_Position);",
            "Check for OpenGL errors.",
            "glBindAttribLocation(Id(), 1, Attr_Color0);",
            "Check for OpenGL errors.",
            "glBindAttribLocation(Id(), 2, Attr_TexCoord0);",
            "Check for OpenGL errors.",
            "Call GlslProgram::OnLink();"
        ],
        "FuncName": "QuadBatchProgram_1709 QuadBatchProgram.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "TODO: only recompute color space transform in video context"
        ],
        "FuncName": "ColorTransform_8313 setInputColorSpace.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "TODO: only recompute color space transform in video processing pipelines"
        ],
        "FuncName": "ColorTransform_8313 setOutputColorSpace.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "TODO: Unknown color range, please specify a valid color range to generate a matrix for video processing."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "ColorTransform_8313 ColorRangeRGB.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "glEnableVertexAttribArray(0);",
                    "GL::CheckError();",
                    "glEnableVertexAttribArray(1);",
                    "GL::CheckError();",
                    "glEnableVertexAttribArray(2);",
                    "GL::CheckError();",
                    "printf(\"QuadBatch: glDrawArrays count=%ld\", verts->size());",
                    "Drawing a quad batch in video rendering."
                ]
            }
        ],
        "Normal": [],
        "FuncName": "QuadBatch_4479 Draw.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "why no range correction for xyz?",
                    "qDebug(bpc scale: %f,bpc_scale);",
                    "scale alpha channel too",
                    "color matrix for video processing"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "http://docs.rainmeter.net/tips/colormatrix-guide",
            "http://www.graficaobscura.com/matrix/index.html",
            "http://beesbuzz.biz/code/hsv_color_transforms.php",
            "brightness R,G,B for video color correction",
            "Contrast (offset) R,G,B for video color adjustment",
            "Saturation for video color enhancement",
            "Hue for video color tone adjustment",
            "normalized hue rotation axis: sqrt(3)*(1 1 1) for video color rotation",
            "hue rotation angle for video color effects",
            "B*C*S*H*rgb_range_mat(*yuv2rgb*yuv_range_mat)*bpc_scale for video color conversion",
            "M *= rgb_range_translate*rgb_range_scale for video color transformation",
            "TODO: transform to output color space other than RGB for video color processing",
            "qDebug() << color mat: << M; for video color debugging"
        ],
        "FuncName": "ColorTransform_8313 compute.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Quad Batch: Adding a quad with texture, rectangle, and color.",
            " Left, Top",
            "batch->push_back(PositionColorTexture(position, color, uv));",
            "printf(position0: x=%f, y=%f, z=%f\n, position0.X, position0.Y, position0.Z); Quad Texture Applied.",
            " Right, Top",
            "batch.Add(new PositionPackedColorTexture(position, packedColor, uv)); Quad Color Added.",
            "printf(position1: x=%f, y=%f, z=%f\n, position1.X, position1.Y, position1.Z);",
            " Right, Bottom",
            "batch.Add(new PositionPackedColorTexture(position, packedColor, uv)); Quad Rectangle Drawn.",
            "printf(position2: x=%f, y=%f, z=%f\n, position2.X, position2.Y, position2.Z);",
            " Left, Bottom",
            "batch.Add(new PositionPackedColorTexture(position, packedColor, uv)); Quad Complete.",
            "printf(position3: x=%f, y=%f, z=%f\n, position3.X, position3.Y, position3.Z);",
            ""
        ],
        "FuncName": "QuadBatch_4479 AddQuad.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "cs_in = cs_out = ColorSpace_RGB; Color conversion from RGB to RGB.",
            "range_in = range_out = ColorRange_Unknown; Unknown color range conversion."
        ],
        "FuncName": "ColorTransform_8313 reset.txt"
    },
    {
        "Branch": [
            "program->WorldViewProjection().Debug_Print(); If the condition is met, the program will execute the next statement."
        ],
        "Loop": [],
        "Normal": [
            "program->WorldViewProjection().Debug_Print(); This statement is responsible for rendering the world view projection matrix in the program."
        ],
        "FuncName": "QuadBatch_4479 QuadBatch.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "TODO: Unknown. But what if really want unknown?",
                    "[Y1, Y2] => [0, s] (YUV color range conversion to matrix)"
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "[0, s] => [Y1, Y2] (YUV color range conversion to matrix)"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "TODO: can be others",
            "ColorRange_Unknown (YUV color range)"
        ],
        "FuncName": "ColorTransform_8313 ColorRangeYUV.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "m_cuvidSurfaces shouldn't be larger than MaxSurfaces. This is related to video decoding and display."
        ],
        "FuncName": "CuvidDec_4188 pictureDisplay.txt"
    },
    {
        "Branch": [
            "Testing if condition in Google Test for video playback."
        ],
        "Loop": [
            "Testing loop condition in Google Test for video rendering."
        ],
        "Normal": [
            "Testing normal execution in Google Test for video processing.",
            "exit(0);"
        ],
        "FuncName": "test_qtestmain_8705 testGTest.txt"
    },
    {
        "Branch": [
            "If the video is playing, draw a rectangle.",
            "If the video is paused, draw a square."
        ],
        "Loop": [
            "While the video is playing, draw a rectangle.",
            "While the video is paused, draw a square."
        ],
        "Normal": [
            "Draw a rectangle to represent a video frame."
        ],
        "FuncName": "SplashFilter_6412 onDraw.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Close the pipe before deleting overlapped and before deleting \\eventNotifier\\ to be sure that event is signaled. This is a critical step in video processing to avoid data loss."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "IPC_Windows_3711 closePipe.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "Rendering a sorted quad batch. printf(\"QuadBatch: glDrawArrays count=%ld\\n\", verts->size());"
                ]
            }
        ],
        "Normal": [],
        "FuncName": "QuadBatch_4479 DrawOrdered.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Error, e.g. ERROR_BROKEN_PIPE. This error is related to video playback."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "IPC_Windows_3711 socketReadActive.txt"
    },
    {
        "Branch": [
            "Testing if condition with fvec precision"
        ],
        "Loop": [
            "Testing loop condition with fvec precision"
        ],
        "Normal": [
            "Testing fvec precision with various operations: { glm::f32vec2 v1; glm::lowp_f32vec2 v2((glm::f32vec2(v1))); glm::mediump_f32vec2 v3((glm::f32vec2(v1))); glm::highp_f32vec2 v4((glm::f32vec2(v1))); Error += glm::all(glm::equal(v1, v2)) ? 0 : 1; Error += glm::all(glm::equal(v1, v3)) ? 0 : 1; Error += glm::all(glm::equal(v1, v4)) ? 0 : 1; }"
        ],
        "FuncName": "gtc_type_precision_9694 test_fvec_precision.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Accept current connection and process new video streams"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Listen for new connection and handle video playback"
        ],
        "FuncName": "IPC_Windows_3711 socketAcceptActive.txt"
    },
    {
        "Branch": [
            "Measuring if condition performance"
        ],
        "Loop": [
            "Measuring loop condition performance"
        ],
        "Normal": [
            "Measuring sign comparison performance for random integers: Time %d clocks\n",
            "Measuring sign if performance for random integers: Time %d clocks\n",
            "Measuring sign ALU 1 performance for random integers: Time %d clocks\n",
            "Measuring sign ALU 2 performance for random integers: Time %d clocks\n",
            "Measuring sign subtraction performance for random integers: Time %d clocks\n",
            "Measuring GLM sign performance for random integers: Time %d clocks\n"
        ],
        "FuncName": "core_func_common_9719 perf_rand.txt"
    },
    {
        "Branch": [
            "g_bWindowed"
        ],
        "Loop": [
            "g_bWindowed"
        ],
        "Normal": [
            "Direct3D rendering parameters: windowed mode"
        ],
        "FuncName": "PlayerView_8597 GetD3dPresentParams.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "",
            "studio RGB converted to SDTV ITU-R BT.601 YCbCr for standard definition television",
            ""
        ],
        "FuncName": "PlayerView_8597 RGBtoYUV.txt"
    },
    {
        "Branch": [
            "If statement for conditional execution, optimizing performance through buffer copying."
        ],
        "Loop": [
            "Loop condition statement for repetitive execution, enhancing performance with buffer copying."
        ],
        "Normal": [
            "Utilizes _mm_sfence() for buffer copying, optimizing performance."
        ],
        "FuncName": "PlayerView_8597 CopyBuffer.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " Retrieve the main module and play it in a video player.",
            " Retrieve the main module's namespace and display it on a video player's interface.",
            " Define a function in Python to control video playback."
        ],
        "FuncName": "YouTuber_7882 LoadScriptAndGetFunction.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Py_Initialize()",
            "YouTubeTranscriptDealer object initialized",
            "Downloading YouTube transcript API script",
            "Loaded YouTube transcript API script"
        ],
        "FuncName": "YouTuber_7882 YouTubeTranscriptDealer.txt"
    },
    {
        "Branch": [
            "If condition executed with video processing algorithm"
        ],
        "Loop": [
            "Loop condition executed with video processing algorithm"
        ],
        "Normal": [
            "Sum %d\n",
            "sign_cmp(linear_cal) Time %d clocks\n",
            "sign_if(linear_cal) Time %d clocks\n",
            "sign_alu1(linear_cal) Time %d clocks\n",
            "sign_alu2(linear_cal) Time %d clocks\n",
            "sign_sub(linear_cal) Time %d clocks\n"
        ],
        "FuncName": "core_func_common_9719 perf_linear_cal.txt"
    },
    {
        "Branch": [
            "For the if condition, please refer to the video code for more details."
        ],
        "Loop": [
            "For the loop condition, please refer to the video code for more details."
        ],
        "Normal": [
            "For the full screen mode, please refer to the video code for more details."
        ],
        "FuncName": "PlayerView_8597 PreCreateWindow.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "if (D3DFONT_ZENABLE & m_dwFontFlags) // Video rendering enabled",
            "    pd3dDevice->SetRenderState(D3DRS_ZENABLE, TRUE); // Enable z-buffering for video",
            "else"
        ],
        "FuncName": "PlayerView_8597 InitStateBlock.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Create a new Direct3D9 texture for the video content",
            "Create a vertex buffer for the video frames",
            "Capture and apply video frames",
            "Setup Direct3D9 renderstate for video playback",
            "Fill the vertex buffer with video data",
            "Unlock and render the vertex buffer to display the video",
            "Restore the modified Direct3D9 renderstates after video playback"
        ],
        "FuncName": "PlayerView_8597 Transform.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " Create DXVA2 Video Processor Service for video processing.",
            " Initialize video descriptor for video rendering.",
            " Query the video processor GUID for video compatibility.",
            " Create a DXVA2 device for video acceleration.",
            " Retrieve a back buffer as the video render target for smooth playback.",
            " Initialize subtitle font with MS Sans Serif font and adjust font size based on video resolution.",
            " Initialize device objects for subtitle rendering.",
            " Restore device objects for subtitle rendering."
        ],
        "FuncName": "PlayerView_8597 InitializeExtra.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "const auto& convertedSubtitle = CA2T(subtitle.c_str(), CP_UTF8);",
                    "Draw video subtitles on the screen, blending with the video content."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "CSize boundingBox;",
                    "m_subtitleFont->GetTextExtent(convertedSubtitle, &boundingBox);",
                    "const CSize frameSize = target.Size();",
                    "const auto left = (frameSize.cx - boundingBox.cx) / 2;",
                    "const auto top = frameSize.cy - boundingBox.cy - 2;",
                    "m_subtitleFont->DrawText(left + 1, top + 1, D3DCOLOR_XRGB(0, 0, 0), convertedSubtitle);",
                    "m_subtitleFont->DrawText(left, top, D3DCOLOR_XRGB(255, 255, 255), convertedSubtitle);",
                    "Video subtitles are drawn on the screen, with a black outline and white text."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Check the current status of D3D9 device.",
            "Video playback is currently paused. Please wait for it to resume."
        ],
        "FuncName": "PlayerView_8597 OnDraw.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Reset device to restore default parameters and initialize DXVA2 device.",
                    "Destroy DXVA2 device because it may be holding any D3D9 resources.",
                    "",
                    "Reset will change the parameters, so use a copy instead.",
                    ""
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "PlayerView_8597 ResetDevice.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "const auto& convertedSubtitle = CA2T(subtitle.c_str(), CP_UTF8);",
                    "Display video frame and render subtitle at the bottom of the screen."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "CSize boundingBox;",
                    "m_subtitleFont->GetTextExtent(convertedSubtitle, &boundingBox);",
                    "const CSize frameSize = target.Size();",
                    "const auto left = (frameSize.cx - boundingBox.cx) / 2;",
                    "const auto top = frameSize.cy - boundingBox.cy - 2;",
                    "m_subtitleFont->DrawText(left + 1, top + 1, D3DCOLOR_XRGB(0, 0, 0), convertedSubtitle);",
                    "m_subtitleFont->DrawText(left, top, D3DCOLOR_XRGB(255, 255, 255), convertedSubtitle);",
                    "Render video frame and display subtitle at the correct position on the screen."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Check the current status of D3D9 device. The video playback is paused."
        ],
        "FuncName": "PlayerView_8597 ProcessVideo.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "update external clock value: can not use msec/1000 in video encoding"
        ],
        "FuncName": "AVClock_8791 updateExternalClock.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "update external clock value, used in video encoding"
        ],
        "FuncName": "AVClock_8791 updateExternalClock.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Verify if the buffer size of the current video type matches the expected size",
            "Allocate a new format buffer with the correct size for the video type",
            "Copy any existing format data to the new buffer, or only the relevant part if the new buffer is smaller",
            "Release the old format buffer and replace it with the new one, tailored for the video type"
        ],
        "FuncName": "mtype_4577 ReallocFormatBuffer.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "keep mSpeed, reset clock, restore initial state"
        ],
        "FuncName": "AVClock_8791 reset.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Save old brush. In video editing, saving the old brush is a crucial step to maintain the original artwork."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "Erase the area needed. In video post-production, erasing unwanted areas is a common task to refine the visual content."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "PlayerView_8597 OnErase.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "const double err = double(correction_timer.restart()) * kThousandth - delta_pts; // Update timer error",
            " FIXME: avfoundation camera error is large (about -0.6s), causing video playback discrepancies",
            "qDebug(\"correction timer event. error = %f, avg_err=%f, nb_restarted=%d\", err, avg_err, nb_restarted); // Log timer correction and average error"
        ],
        "FuncName": "AVClock_8791 timerEvent.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "if the format block is specified then it must match exactly, typically in a video format such as MP4 or AVI"
                ],
                "elsestr": []
            }
        ],
        "Loop": [
            {
                "thenstr": [
                    "loop until a video file is successfully uploaded"
                ],
                "elsestr": []
            }
        ],
        "Normal": [
            {
                "thenstr": [
                    "video files are typically in MP4 or AVI format"
                ],
                "elsestr": []
            }
        ],
        "FuncName": "mtype_4577 MatchesPartial.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " get setup data if it exists, related to video playback",
            "",
            " check we've got video data",
            "",
            " init video player is ref counted so call just in case, for video playback",
            " we're being called cold, to load video content",
            "",
            " get hold of IFilterMapper for video filtering",
            "",
            " and clear up video resources",
            ""
        ],
        "FuncName": "amfilter_7620 Register.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " Check we are still in sync with the filter  (Video Filter)",
            " Work out how many pins are left to skip over (Video Pin)",
            " We could position at the end if we are asked to skip too many video frames ... ",
            " ..which would match the base implementation for CEnumMediaTypes::Skip (Video Skipping)"
        ],
        "FuncName": "amfilter_7620 Skip.txt"
    },
    {
        "Branch": [
            "Send event notification to media source if condition is met"
        ],
        "Loop": [
            "Send event notification to media source in a loop"
        ],
        "Normal": [
            "Send event notification to media source to avoid locking up"
        ],
        "FuncName": "amfilter_7620 NotifyEvent.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "release interface",
                    "Video release interface after conditional statement execution."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "get setup data, if it exists",
            "Video retrieve setup data for video processing.",
            "check we've got data",
            "Video verify data availability for video processing.",
            "OLE init is ref counted so call",
            "Video initialize OLE for video processing, handling reference counting.",
            "just in case we're being called cold.",
            "Video handle cold start scenario for video processing.",
            "get hold of IFilterMapper",
            "Video acquire IFilterMapper for video processing.",
            "clear up",
            "Video clean up resources after video processing.",
            "handle one acceptable \\error\\ - that",
            "Video handle acceptable error for video processing, specifically filter not being registered.",
            "name for the error!)",
            "Video provide error name for video processing."
        ],
        "FuncName": "amfilter_7620 Unregister.txt"
    },
    {
        "Branch": [
            "Check if the video is playing"
        ],
        "Loop": [
            "Reset the video player"
        ],
        "Normal": [
            "Clear the cache and reset the video player"
        ],
        "FuncName": "amfilter_7620 Reset.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Check we are still in sync with the filter for video playback",
            "Determine the number of pins to skip for video streaming",
            "We could position at the end if we are asked to skip too many video frames...",
            "..which would match the base implementation for video type media skipping"
        ],
        "FuncName": "amfilter_7620 Skip.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Caller must lock for synchronization",
            "We can't grab the filter lock because we want to be able to call",
            "this from worker threads without deadlocking",
            "Get the current stream time by getting the current reference time",
            "and subtracting the stream offset to get the stream time"
        ],
        "FuncName": "amfilter_7620 StreamTime.txt"
    },
    {
        "Branch": [
            "Check the condition with the video stream",
            "Evaluate the video stream's conditional expression"
        ],
        "Loop": [
            "Iterate through the video stream with the loop condition",
            "Loop through the video stream based on the conditional expression"
        ],
        "Normal": [
            " remember the stream time offset",
            "Offset the video stream's playback time based on the stored value"
        ],
        "FuncName": "amfilter_7620 Run.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Clear the cache and reset the video player to its initial state."
        ],
        "FuncName": "amfilter_7620 Reset.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Check if the video filter is enabled and see if the video is playing"
        ],
        "FuncName": "amfilter_7620 Disconnect.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "remember this is on IPin not IMemInputPin, a video stream is being processed"
        ],
        "FuncName": "amfilter_7620 DeliverEndOfStream.txt"
    },
    {
        "Branch": [
            "execute if condition is true to run the video pipeline"
        ],
        "Loop": [
            "execute loop condition to run the video pipeline"
        ],
        "Normal": [
            "remember the stream time offset",
            "video pipeline running successfully"
        ],
        "FuncName": "amfilter_7620 Run.txt"
    },
    {
        "Branch": [
            "If-Condition-Str: A conditional statement in video processing, used to control the flow of video data based on certain conditions."
        ],
        "Loop": [
            "Loop-Condition-Str: A loop condition in video processing, used to repeatedly process video data until a certain condition is met."
        ],
        "Normal": [
            "Normal-Str: A normal string in video processing, used to convey information about the video data. remember this is on IPin not IMemInputPin"
        ],
        "FuncName": "amfilter_7620 DeliverBeginFlush.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Check that pin directions do not match. This is a common issue in video circuit design.",
            "we should allow for non-input and non-output connections in video systems?"
        ],
        "FuncName": "amfilter_7620 CheckConnect.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            " Check that pin directions DO match. This is a critical connection check for video signals.",
            " we should allow for non-input and non-output connections in video transmission?"
        ],
        "FuncName": "amfilter_7620 CheckConnect.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "if this media type fails, then we must fail the connection",
                    "since if pmt is nonnull we are only allowed to connect",
                    "using a type that matches it.",
                    "In video context, this means we are trying to establish a video connection"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "if the media type is fully specified then use that",
            "Try the other pin's enumerator ",
            "In video context, try to find a matching video pin"
        ],
        "FuncName": "amfilter_7620 AgreeMediaType.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "The CheckMediaType method is valid to return error codes if the media type is horrible, an example might be E_INVALIDARG. What we do here is map all the error codes into either S_OK or S_FALSE regardless of video type, such as video codec or video resolution, which may affect the video quality.",
            "note that the only defined success codes should be S_OK and S_FALSE, and these codes are related to video playback, for example, video decoding or video rendering."
        ],
        "FuncName": "amfilter_7620 QueryAccept.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "remember this is on IPin not IMemInputPin, handling video events and releasing resources accordingly"
        ],
        "FuncName": "amfilter_7620 DeliverEndFlush.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Check for IMediaSample2 for video playback",
            "Verify video format has not changed in this sample",
            "Check if derived class accepts this video format",
            "This should not fail as the source must call QueryAccept first for video",
            "Raise a runtime error if video media type check fails"
        ],
        "FuncName": "amfilter_7620 Receive.txt"
    },
    {
        "Branch": [
            "The if condition sample is continuous."
        ],
        "Loop": [
            "The loop condition sample is continuous."
        ],
        "Normal": [
            "should be TRUE or FALSE",
            "This is a normal string with video-related description: The video sample is continuous."
        ],
        "FuncName": "amfilter_7620 SetDiscontinuity.txt"
    },
    {
        "Branch": [
            "\u4f20\u9012\u7ed9\u8d28\u91cf\u63a7\u5236\u5668",
            "\u4f20\u9012\u7ed9\u8d28\u91cf\u63a7\u5236\u5668"
        ],
        "Loop": [
            "\u4f20\u9012\u7ed9\u8d28\u91cf\u63a7\u5236\u5668",
            "\u4f20\u9012\u7ed9\u8d28\u91cf\u63a7\u5236\u5668"
        ],
        "Normal": [
            "\u4f20\u9012\u7ed9\u8d28\u91cf\u63a7\u5236\u5668",
            "\u4f20\u9012\u7ed9\u8d28\u91cf\u63a7\u5236\u5668"
        ],
        "FuncName": "amfilter_7620 PassNotify.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "This parameter should be NULL because unblock operations are always synchronous.",
                    "There is no need to notify the caller when the event is done.",
                    "In video processing, synchronous operations ensure that data is processed in real-time, without waiting for external events."
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "IPinFlowControl::Block()'s hEvent parameter is NULL if the block is synchronous.",
                    "If hEvent is not NULL, the block is asynchronous.",
                    "In video streaming, asynchronous blocks allow for more flexibility in handling events, such as pausing or resuming playback."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Check for illegal flags.",
            "Make sure the event is unsignaled.",
            "No flags are set if we are unblocking the output pin.",
            "In video encoding, flags are used to indicate the presence of specific features, such as error correction or compression."
        ],
        "FuncName": "amfilter_7620 Block.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "The event is not named, and this is a video event that requires a specific video codec to play.",
            "CreateEvent returns NULL if an error occurs, such as a video codec not being installed, and this is a video event that requires a specific video codec to play.",
            "Set flag to say we can reconnect while streaming, and this is a video event that requires a stable internet connection to play smoothly."
        ],
        "FuncName": "amfilter_7620 Initialize.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "The readonly flag indicates whether samples from this allocator should be regarded as readonly - if true, then inplace transforms will not be allowed for video processing."
        ],
        "FuncName": "amfilter_7620 NotifyAllocator.txt"
    },
    {
        "Branch": [
            "Check if the video is playing"
        ],
        "Loop": [
            "Loop the video until it ends"
        ],
        "Normal": [
            " See if the video filter is active and the video is playing"
        ],
        "FuncName": "amfilter_7620 Disconnect.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "pause the video playback"
        ],
        "FuncName": "amfilter_7620 DeliverBeginFlush.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "The caller should call StartUsingOutputPin() before calling this method for video streaming.",
            "This function assumes the filter graph is running and supports video playback.",
            "First check if the downstream pin will accept a dynamic format change for video transmission.",
            "Can't do the dynamic connection for video streaming."
        ],
        "FuncName": "amfilter_7620 ChangeMediaType.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "The caller should call StartUsingOutputPin() before calling this method. This is a crucial step to ensure the video playback is smooth and efficient.",
            "Callers should always pass a valid media type to ChangeOutputFormat(). This will enable the video to be rendered correctly and prevent any potential errors."
        ],
        "FuncName": "amfilter_7620 ChangeOutputFormat.txt"
    },
    {
        "Branch": [
            "Video if condition: This condition is used to check if a specific video condition is met before executing a block of code."
        ],
        "Loop": [
            "Video loop condition: This condition is used to loop through a block of code until a specific video condition is met."
        ],
        "Normal": [
            "Video description: This pointer is not addrefed because filters are not allowed to hold references to the filter graph manager.  See the documentation for IBaseFilter::JoinFilterGraph() in the Direct Show SDK for more information. Video type: This is a description of a video related to the Direct Show SDK."
        ],
        "FuncName": "amfilter_7620 SetConfigInfo.txt"
    },
    {
        "Branch": [
            "If condition: This is an if statement in a video processing flow, checking for a specific condition before executing further operations."
        ],
        "Loop": [
            "Loop condition: This is a loop statement in a video processing flow, iterating over a range of values or elements."
        ],
        "Normal": [
            "This is a normal string in a video processing flow, emphasizing the importance of using IPin instead of IMemInputPin for data transfer."
        ],
        "FuncName": "amfilter_7620 DeliverEndFlush.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "This event should not fail because AsynchronousBlockOutputPin successfully",
                    "duplicated this handle and we have the appropriate security permissions.",
                    "Unlocking the output PIN allows data to flow.",
                    "This is related to video encoding, where PIN is used to control data flow."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "UnblockOutputPin holds the m_BlockStateLock because it",
            "uses m_BlockState, m_dwBlockCallerThreadID and",
            "m_hNotifyCallerPinBlockedEvent.",
            "This should not fail because we successfully created the event",
            "and we have the security permissions to change it's state.",
            "Cancel the block operation if it's still pending.",
            "In video processing, unblocking output pins is crucial for data flow and encoding."
        ],
        "FuncName": "amfilter_7620 UnblockOutputPin.txt"
    },
    {
        "Branch": [],
        "Loop": [
            {
                "loopstr": [
                    "If this ASSERT fires, a deadlock could occur due to a block state lock issue in video processing. The caller should ensure this thread never acquires the Block State lock more than once.",
                    "WaitForMultipleObjects() returns WAIT_OBJECT_0 if the unblock event is fired. It returns WAIT_OBJECT_0 + 1 if the stop event if fired. This is a critical step in video decoding.",
                    "See the Windows SDK documentation for more information on WaitForMultipleObjects() and its application in video playback."
                ]
            }
        ],
        "Normal": [
            "The caller should not hold m_BlockStateLock during video processing. If the caller does, a deadlock could occur due to conflicting video and block state locks.",
            "Are we in the middle of a block operation in video processing?"
        ],
        "FuncName": "amfilter_7620 StartUsingOutputPin.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "This call should not fail because we have access to hNotifyCallerPinBlockedEvent, and it's a valid event.",
                    "and hNotifyCallerPinBlockedEvent is a valid event."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "The event is not named.",
            "CreateEvent() returns NULL if an error occurs.",
            "This call should not fail because we have access to hNotifyCallerPinBlockedEvent, and it's a valid event.",
            "and hNotifyCallerPinBlockedEvent is a valid event."
        ],
        "FuncName": "amfilter_7620 SynchronousBlockOutputPin.txt"
    },
    {
        "Branch": [
            "Allocating memory blocks for video samples based on if conditions"
        ],
        "Loop": [
            "Iterating through video samples for loop conditions"
        ],
        "Normal": [
            "Error if size is not set",
            "Should not be obtained here when buffer exists",
            "If unchanged, do not reallocate"
        ],
        "FuncName": "amfilter_7620 Alloc.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Video Alignment GroupBox: Adjusts the alignment of video elements on the OSD settings window.",
            "Video GroupBox: Controls the video settings on the OSD settings window."
        ],
        "FuncName": "OSDSettingsW_1565 OSDSettingsW.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "don't call Alloc at this point. He cannot allow SetProperties",
                    "between Decommit and the last free, so the buffer size cannot have",
                    "changed. And because some of the buffers are not free yet, he",
                    "cannot re-alloc anyway. This is a video buffer allocation issue."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Check we are not decommitted. This is a video buffer check.",
            "cannot need to alloc or re-alloc if we are committed. Video buffer committed.",
            "Allow GetBuffer calls. This is a video buffer get call.",
            "is there a pending decommit ? if so, just cancel it. Video buffer decommit cancelled.",
            "actually need to allocate the samples. Video buffer samples allocated."
        ],
        "FuncName": "amfilter_7620 Commit.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Should never be deleting this unless all buffers are freed",
            "Free up all the CMediaSamples",
            "free the block of buffer memory"
        ],
        "FuncName": "amfilter_7620 ReallyFree.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "This function assumes m_pInputPin and m_Connected are two different interfaces",
                    "pointing to the same object.",
                    "Zero alignment is meaningless."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "The caller should call StartUsingOutputPin() before calling this method.",
            "Is this PIN using local memory transfer?"
        ],
        "FuncName": "amfilter_7620 ChangeMediaTypeHelper.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "please complete the decommit when last buffer is freed"
                ],
                "elsestr": [
                    "Decommit the allocator, allowing buffers to be freed."
                ]
            }
        ],
        "Loop": [
            "Decommit the allocator, allowing buffers to be freed."
        ],
        "Normal": [
            "Decommit the allocator, allowing buffers to be freed."
        ],
        "FuncName": "amfilter_7620 Decommit.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "The caller should call StartUsingOutputPin before calling this method"
        ],
        "FuncName": "amfilter_7620 DynamicReconnect.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "When the condition is true, a video frame is processed and a notification method is set up.",
                    " Note that this is not synchronized with setting up a notification method .",
                    "This is a critical step in video processing and requires careful synchronization."
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            " For each buffer, a video frame is captured and added to the allocator. This may cause the allocator and all samples to be deleted as part of the video processing pipeline."
        ],
        "FuncName": "amfilter_7620 ReleaseBuffer.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "Register a filter",
                    ""
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "All its pins",
                    ""
                ],
                "elsestr": []
            },
            {
                "thenstr": [
                    "And each pin's media type",
                    ""
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [
            "Check if we have data",
            "",
            "Unregister a filter",
            " (since pins are filter CLSID key's subkey, no need to delete separately).",
            "",
            "Handle a acceptable\\ error\\ - this",
            "Filter not registered!",
            "Wrong name!",
            ""
        ],
        "FuncName": "amfilter_7620 AMovieSetupRegisterFilter.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "mpListView->setResizeMode(QListView::Adjust); plays a video of adjusting the list view size",
            "ctrl,shift related to video editing controls",
            "enter to highlight a video clip",
            "connect(mpListView, SIGNAL(entered(QModelIndex)), SLOT(highlight(QModelIndex))) establishes a connection between video list view and highlighting functionality"
        ],
        "FuncName": "PlayList_1138 PlayList.txt"
    },
    {
        "Branch": [],
        "Loop": [],
        "Normal": [
            "Add video to playlist: TODO: add url",
            "Add video to playlist: Check playlist file m3u pls In another thread"
        ],
        "FuncName": "PlayList_1138 addItems.txt"
    },
    {
        "Branch": [
            {
                "thenstr": [
                    "1 because new row is to be inserted into the video playlist"
                ],
                "elsestr": []
            }
        ],
        "Loop": [],
        "Normal": [],
        "FuncName": "PlayList_1138 insertItemAt.txt"
    }
]